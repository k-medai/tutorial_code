{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "039db339-50ad-4a62-a0f2-e89dff130846",
   "metadata": {},
   "source": [
    "# Chapter 3 에서 배울 내용\n",
    "\n",
    "1. **데이터 로더 제작**  \n",
    "   - 모델 학습을 위한 데이터 로더 설계 및 구현  \n",
    "   - 분자 데이터 분류를 위한 사전 지식 이해\n",
    "\n",
    "---\n",
    "2. **모델 제작**  \n",
    "    - 분자 특성 분류/회귀 예측을 위한 모델 아키텍처 설계 \n",
    "    - MLP, CNN, RNN, GNN 등 다양한 모델 활용 방법  \n",
    "    - 입력 데이터 처리 및 모델에 맞는 출력 형식 설정\n",
    "\n",
    "---\n",
    "3. **학습 및 평가**\n",
    "   - 모델 학습을 위한 손실 함수와 최적화 알고리즘 설정  \n",
    "   - 교차 검증, 정확도, 정밀도, 재현율, F1 스코어 등 다양한 평가 지표 활용  \n",
    "   - 과적합 방지를 위한 기법 (예: Dropout, 정규화, 데이터 증강 등)\n",
    "   - 모델 성능 평가 \n",
    "    \n",
    "---\n",
    "4. **결과 저장**\n",
    "    - 학습 로그 및 평가 결과 기록  \n",
    "    - 결과 시각화 및 분석 도구 사용 (예: Loss/Accuracy 그래프, confusion matrix 등)\n",
    "    - 모델을 실험적 환경에서 재사용할 수 있도록 파일 포맷으로 저장 (예: `.pt`, `.h5` 등) \n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac4ddb8e-caeb-4584-8b37-41bb7a90deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, GINConv, GATConv, global_max_pool as gmp, global_add_pool as gap\n",
    "\n",
    "from tabulate import tabulate\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba7b0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf86b5c-da09-4700-9d76-378eb4087c28",
   "metadata": {},
   "source": [
    "## 1) 데이터 로더 제작\n",
    "\n",
    "데이터 로더(Data Loader)는 머신러닝/딥러닝 모델 학습에서 데이터를 효율적으로 불러오고 처리하기 위한 도구다. \n",
    "\n",
    "일반적으로 `PyTorch`와 같은 프레임워크에서 제공되며, 대규모 데이터셋을 다룰 때 데이터를 배치 단위로 나누거나 전처리 작업을 자동화하는 데 사용된다.\n",
    "\n",
    "데이터 로더를 사용하는 이유는 크게 다음과 같다.\n",
    "\n",
    "---\n",
    "1. **미니배치 생성**  \n",
    "   - 데이터를 미니배치 단위로 나누어 처리하여 학습 속도와 메모리 효율성을 높임\n",
    "   - 배치 크기가 작으면 메모리 사용량이 적으나, 학습 시간이 길어질 수 있음\n",
    "   - 배치 크기가 크면 학습 속도가 빨라질 수 있으나, 메모리 사용량이 증가함\n",
    "\n",
    "2. **데이터 셔플링**  \n",
    "   - 학습 데이터 순서를 매 에포크마다 변경해 모델의 일반화 성능을 향상\n",
    "   - 학습 시 특정 순서나 패턴으로 인해 모델이 편향되거나 과적합되지 않도록 하기 위해 사용됨.\n",
    "   - 검증 및 테스트 데이터에서는 **shuffle을 사용하지 않음** (결과 재현성을 위해)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "619051fe-e66a-45dd-b436-6dbb30890aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader_dataset(data_list, batch_size, shuffle=False):\n",
    "    \"\"\"\n",
    "    DataLoader로 변경\n",
    "    \"\"\"\n",
    "    collate = Batch.from_data_list(data_list)\n",
    "    loader = DataLoader(data_list, batch_size=batch_size, collate_fn=collate, shuffle=shuffle)\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edda7c6-286b-4359-bdd8-675de34b42e0",
   "metadata": {},
   "source": [
    "본 튜토리얼에서는 ESOL 데이터셋을 예시로 사용한다.\n",
    "\n",
    "먼저, Chapter2에서 저장한 데이터들을 불러와 data loader를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18d05896-fa45-4575-81bd-679b412e2e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(dataset_name, data_type='Graph', batch_size=256):\n",
    "    data_path = f'dataset/{dataset_name}/processed/'\n",
    "    train_dataset = torch.load(os.path.join(data_path, f'{dataset_name}_{data_type}_train.pt'))\n",
    "    valid_dataset = torch.load(os.path.join(data_path, f'{dataset_name}_{data_type}_valid.pt'))\n",
    "    test_dataset = torch.load(os.path.join(data_path, f'{dataset_name}_{data_type}_test.pt'))    \n",
    "\n",
    "    if data_type == 'Descriptors':  # Descriptors 데이터를 처리할 경우 scaling 필요\n",
    "        # Step 1: Descriptors 데이터에서 x 값들만 추출\n",
    "        raw_features_train = [data.x.view(-1).numpy() for data in train_dataset]\n",
    "        raw_features_valid = [data.x.view(-1).numpy() for data in valid_dataset]\n",
    "        raw_features_test = [data.x.view(-1).numpy() for data in test_dataset]\n",
    "        # print(raw_features_train.shape)\n",
    "\n",
    "        # Step 2: 스케일링을 위한 StandardScaler 적용\n",
    "        # scaler = StandardScaler()\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_features_train = scaler.fit_transform(raw_features_train)  # 학습 데이터에 맞춰 스케일링\n",
    "        scaled_features_valid = scaler.transform(raw_features_valid)  # 검증 데이터는 fit하지 않고 transform만 적용\n",
    "        scaled_features_test = scaler.transform(raw_features_test)  # 테스트 데이터도 동일\n",
    "\n",
    "        # Step 3: 스케일링된 데이터를 원본 데이터셋에 반영\n",
    "        for i, data in enumerate(train_dataset):\n",
    "            data.x = torch.tensor(scaled_features_train[i], dtype=torch.float).view(1, -1)\n",
    "        for i, data in enumerate(valid_dataset):\n",
    "            data.x = torch.tensor(scaled_features_valid[i], dtype=torch.float).view(1, -1)\n",
    "        for i, data in enumerate(test_dataset):\n",
    "            data.x = torch.tensor(scaled_features_test[i], dtype=torch.float).view(1, -1)       \n",
    "\n",
    "    train_loader = loader_dataset(data_list=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = loader_dataset(data_list=valid_dataset, batch_size=batch_size, shuffle=False) \n",
    "    test_loader = loader_dataset(data_list=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fedc05b-8092-41d7-b129-cc5749baaf6a",
   "metadata": {},
   "source": [
    "`dataset_name` : 불러올 데이터셋의 이름 입력\n",
    "\n",
    "`data_type` : Chapter2 에서 저장한 데이터셋 유형 (Token, Fingerprint, Descriptors, Graph) 중 하나를 선택\n",
    "\n",
    "`batch_size` : 한번에 처리할 샘플 개수를 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35d9feb-50b7-4ca8-b21d-b164bd6880df",
   "metadata": {},
   "source": [
    " Graph loader가 어떻게 구성되어 있는지 확인해본다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d22cdf9-95f6-44fc-b560-35ada156618a",
   "metadata": {},
   "source": [
    "### Graph Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44f70bdd-14d0-452b-bafd-0c03dcee9008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[4311, 9], edge_index=[2, 9322], edge_attr=[9322, 3], smiles=[128], y=[128, 1], batch=[4311], ptr=[129])\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader = get_dataloader(dataset_name = 'bace', data_type='Graph', batch_size = 128)\n",
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465530c0-e652-40e2-85c1-0655920e18e0",
   "metadata": {},
   "source": [
    "- x: 그래프의 노드 feature\n",
    "- edge_index: 그래프의 두 노드 간 연결(edge) 정보\n",
    "- edge_attr : 노드 간 연결(edge)의 feature\n",
    "- smiles : 그래프가 표현하는 분자의 smiles\n",
    "- y : task에 대한 label\n",
    "- batch : batch 내의 총 노드 개수\n",
    "- ptr : 각 그래프의 시작 노드의 위치. 그래프 개수(batch size) + 1 의 길이이며, 마지막 값은 batch에 포함된 전체 노드의 개수를 의미."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad728f0f-5fe3-417a-b1d0-19e185789a19",
   "metadata": {},
   "source": [
    "다른 표현형들의 경우 feature는 x에, label은 y에 저장되어있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80134772-9fea-4878-8379-8dd8dca2b32d",
   "metadata": {},
   "source": [
    "## 2) 모델 제작\n",
    "\n",
    "분자의 표현형에 따라 데이터 타입이 달라지므로, 각기 다른 모델을 사용하여야 한다.\n",
    "\n",
    "예를 들어 Graph 형태의 데이터는 Graph를 처리할 수 있는 GNN을, String Tokenization 형태의 경우 순서 정보를 반영할 수 있는 1D CNN, RNN 등을 사용할 수 있다.\n",
    "\n",
    "가장 기본적인 모델인 MLP를 먼저 사용해보자\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dc49a6-887d-462f-b528-434774318f1c",
   "metadata": {},
   "source": [
    "1. Fingerprint\n",
    "\n",
    "- Fingerprint는 분자의 특성을 단순히 vector 형태로 나타낸 것이다.\n",
    "- 따라서 기본 모델인 MLP로 학습하는 것이 적합하다.\n",
    "- 아래에 정의한 MLP 차원 및 layer 개수는 예시이므로, 데이터셋에 적합하게 수정하여 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28f8637b-c6a7-4e5f-a7a7-16698405ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 \n",
    "class MLP(nn.Module): \n",
    "    def __init__(self, input_dim, hidden_dim, num_classes, dropout_rate=0.5): \n",
    "        super(MLP, self).__init__() \n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim) # input feature가 4개 \n",
    "        self.layer2 = nn.Linear(hidden_dim,hidden_dim*2)\n",
    "        self.layer3 = nn.Linear(hidden_dim*2,hidden_dim*1)\n",
    "        self.layer4 = nn.Linear(hidden_dim*1, num_classes) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self,data): # 모델에서 실행되어야 하는 계산을 정의\n",
    "        x = self.layer1(data.x.float()) # data의 feature가 들어있는 x 만 받아옴, 연산 시 데이터 타입을 일치시키기 위해 float() \n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)  \n",
    "        x = self.layer2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)  \n",
    "        x = self.layer3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer4(x)   # 출력층\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb80a3ac-f972-4578-a51e-ed3ca3060854",
   "metadata": {},
   "source": [
    "- `input dim` : 모델의 입력 차원을 의미하며, 데이터 feature의 차원에 따라 결정되므로 적용하려는 데이터에 맞게 설정한다. \n",
    "\n",
    "- `hidden dim` : 입력 층을 거친 후 은닉층의 차원을 설정하는 부분이다. 이 파라미터와 layer 개수에 따라 모델의 capacity가 결정된다.\n",
    "\n",
    "- `num_classes` : 분류할 클래스의 개수를 나타낸다.\n",
    "\n",
    "- `dropout_rate` : dropout은 일부 뉴런을 랜덤으로 비활성화 하여 과적합을 방지하기 위한 기법이다. 이 파라미터는 비활성화 할 뉴런의 비율을 결정한다.\n",
    "\n",
    "- 각 레이어 사이에 비선형성을 추가하기 위해 활성화 함수가 포함된다.(예시에서는 ReLU사용)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "학습 전, 입력 차원을 결정하기 위해 data loader에서 모델에 학습할 정보를 담고 있는 x의 shape를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34bf5c1b-4fa0-4fea-b466-066b756cdd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[128, 1024], y=[128, 1], smiles=[128], batch=[128], ptr=[129])\n"
     ]
    }
   ],
   "source": [
    "# Fingerprint Loader 확인\n",
    "train_loader, valid_loader, test_loader = get_dataloader(dataset_name = 'bace', data_type='Fingerprint', batch_size = 128)\n",
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a6c2c6-4e92-495c-a1ef-06237c3014f2",
   "metadata": {},
   "source": [
    "데이터의 입력을 나타내는 x의 차원이 1024이므로 `input_dim` = 1024가 된다. 또한 bace는 이진 분류이므로 `num_classes` = 1로 설정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9f9266-3511-426f-b351-9d926252adc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (layer1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (layer2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (layer3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (layer4): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_model1 = MLP(input_dim=1024, hidden_dim = 128, num_classes = 1, dropout_rate=0.5)\n",
    "fp_model1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbc719c-4792-4b0d-95af-7ca249c51b39",
   "metadata": {},
   "source": [
    "임의로 설정된 `hidden_dim` 및 `dropout_rate`을 자유롭게 설정하여 모델을 만들어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae49930-16c0-4c2e-9c20-e9f0ef3f24ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (layer1): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  (layer2): Linear(in_features=32, out_features=64, bias=True)\n",
       "  (layer3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (layer4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.7, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_model2 = MLP(input_dim=1024, hidden_dim = 32, num_classes = 1, dropout_rate=0.7)\n",
    "fp_model2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67c64d0-b8e0-4308-996a-40f221f00589",
   "metadata": {},
   "source": [
    "2. Descriptors\n",
    "\n",
    "- Descriptors 역시 분자의 특성을 vector 형태로 나타낸 것이므로 MLP를 사용하여 학습한다.\n",
    "- 사전 정의한 MLP 모델에서 입력 차원만을 변경하여 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecd05469-c360-47aa-b239-967d00bee509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[128, 210], y=[128, 1], smiles=[128], batch=[128], ptr=[129])\n"
     ]
    }
   ],
   "source": [
    "# Descriptors Loader 확인\n",
    "train_loader, valid_loader, test_loader = get_dataloader(dataset_name = 'bace', data_type='Descriptors', batch_size = 128)\n",
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86863ae3-7318-4267-8449-68f9afa8bf69",
   "metadata": {},
   "source": [
    "descriptor의 x 차원은 210이므로 `input_dim` = 210이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c230a3d0-667a-4be3-8d96-2347b908423e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (layer1): Linear(in_features=210, out_features=128, bias=True)\n",
       "  (layer2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (layer3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (layer4): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_model = MLP(input_dim=210, hidden_dim = 128, num_classes = 1, dropout_rate=0.2)\n",
    "ds_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455662e3-5149-4264-86ad-34b37b2f608c",
   "metadata": {},
   "source": [
    "3. Token\n",
    "\n",
    "- Token은 분자를 문자열로 나타낸 데이터 형태이다.\n",
    "- 따라서 문자열의 순서를 반영할 수 있는 1D CNN을 사용하여 학습해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab2c3929-ae87-4499-835a-bd3893a47dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d(nn.Module):\n",
    "    def __init__(self, vocab_num, seq_len, emb_dim, hidden_size, kernel_size, num_classes):\n",
    "        super(Conv1d, self).__init__()\n",
    "        \n",
    "        # init\n",
    "        self.relu = nn.ReLU()\n",
    "        self.n_filters = hidden_size\n",
    "        \n",
    "        # Embedding Layer\n",
    "        self.embedding = nn.Embedding(vocab_num, emb_dim)\n",
    "        \n",
    "        # Conv1d Layers\n",
    "        self.layer1 = nn.Conv1d(in_channels=seq_len, out_channels=hidden_size, kernel_size=kernel_size)\n",
    "        self.layer2 = nn.Conv1d(in_channels=hidden_size, out_channels=hidden_size * 2, kernel_size=kernel_size)\n",
    "        self.layer3 = nn.Conv1d(in_channels=hidden_size * 2, out_channels=hidden_size * 3, kernel_size=kernel_size)\n",
    "        \n",
    "        # Pooling Layer\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, data):\n",
    "        # Embedding Layer\n",
    "        x = self.embedding(data.x)  # Input shape: (batch_size, seq_len)\n",
    "        \n",
    "        # Conv1d Layers\n",
    "        x = self.relu(self.layer1(x))  # (batch_size, hidden_size, new_seq_len)\n",
    "        x = self.relu(self.layer2(x))  # (batch_size, hidden_size * 2, smaller_seq_len)\n",
    "        x = self.relu(self.layer3(x))  # (batch_size, hidden_size * 3, more smaller_seq_len)\n",
    "        \n",
    "        # Pooling & Flatten\n",
    "        x = self.pool(x).view(-1, self.n_filters * 3) # (batch, hidden_size * 3)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        x = self.classifier(x)  # (batch_size, 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648afcbf-6376-4605-b264-5085a5e8b70c",
   "metadata": {},
   "source": [
    "- `vocab_num` : 문자열을 구성하는 단어의 종류를 입력한다. chapter2에서 string tokenization 단계에서 출력한 단어집에서 단어의 종류를 알 수 있다. bace의 경우 Unkown 포함 39개가 있다.\n",
    "\n",
    "- `emb_dim` : 입력된 단어가 임베딩 될 차원을 결정한다.\n",
    "\n",
    "- `hidden_dim` : 임베딩 된 단어를 학습 시킬 때 은닉층의 차원을 설정한다.\n",
    "\n",
    "- `kernel_size` : kernel이 한 번에 읽을 시퀀스의 길이를 정의하며, 작을 수록 세밀한 패턴을, 클 수록 넓은 문맥을 포착한다.\n",
    "\n",
    "- `num_classes` : 분류할 클래스의 개수를 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04c821c7-048a-4470-8622-0b13cf821ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[128, 178], y=[128, 1], smiles=[128], batch=[128], ptr=[129])\n"
     ]
    }
   ],
   "source": [
    "# Token Loader 확인\n",
    "train_loader, valid_loader, test_loader = get_dataloader(dataset_name = 'bace', data_type='Token', batch_size = 128)\n",
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6351be38-70ec-4641-a672-30a500c14eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(\n",
       "  (relu): ReLU()\n",
       "  (embedding): Embedding(39, 128)\n",
       "  (layer1): Conv1d(178, 128, kernel_size=(1,), stride=(1,))\n",
       "  (layer2): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "  (layer3): Conv1d(256, 384, kernel_size=(1,), stride=(1,))\n",
       "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Conv1d(vocab_num=39, seq_len=178, emb_dim=128, hidden_size = 128, kernel_size = 1, num_classes=1)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c776c95-cdef-4e51-8a2e-1fe568ec374e",
   "metadata": {},
   "source": [
    "4. Graph\n",
    "\n",
    "- Graph는 분자를 구성하는 각 원자를 노드(node), 원자들의 결합을 엣지(edge)로 나타낸 데이터 형태이다.\n",
    "- Graph 형태의 데이터를 처리할 수 있는 신경망인 Graph Neural Network(GNN)을 사용하여야 한다.\n",
    "- 이번 예시에서는 GNN의 예시 중 하나인 GIN을 구현해볼 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fc9a78-9705-46bf-be00-143ea9f5203a",
   "metadata": {},
   "source": [
    "- GNN의 입력에는 노드의 특징 차원이 필요하다. data loader를 print하여 노드 x의 feature 차원을 출력해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a780b7e-0e2e-4d4a-9bcf-948d899b9f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[4355, 9], edge_index=[2, 9442], edge_attr=[9442, 3], smiles=[128], y=[128, 1], batch=[4355], ptr=[129])\n"
     ]
    }
   ],
   "source": [
    "# Descriptors Loader 확인\n",
    "train_loader, valid_loader, test_loader = get_dataloader(dataset_name = 'bace', data_type='Graph', batch_size = 128)\n",
    "for data in train_loader:\n",
    "        print(data)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec57a2c-74cd-46af-a0fa-69dfe65fc03f",
   "metadata": {},
   "source": [
    "- GNN은 각 노드들의 정보 전파 및 종합이 일어나는 gnn layer와, gnn layer가 생성한 표현을 바탕으로 분류 및 회귀 작업이 일어나는 feed forward network(ffn)로 구성된다. 따라서 `hidden_dim`은 gnn의 은닉층 차원을, `ffn_hidden`은 ffn layer의 은닉층의 차원을 지정하는 파라미터이다.\n",
    "- `input_dim` : 노드 feature의 차원을 입력한다.\n",
    "- `num_classes`: ffn layer의 마지막 차원을 결정하는 파라미터이므로, 분류하고자 하는 클래스의 개수를 입력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23e028f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINConvNet(torch.nn.Module):\n",
    "    \"\"\"Graph Isomorphism Network class with 3 GINConv layers and 2 linear layers\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, dim_h, dropout=0.2):\n",
    "        \"\"\"Initializing GIN class\n",
    "\n",
    "        Args:\n",
    "            dim_h (int): the dimension of hidden layers\n",
    "        \"\"\"\n",
    "        super(GINConvNet, self).__init__()\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(input_dim, dim_h), nn.BatchNorm1d(dim_h), ReLU(), Linear(dim_h, dim_h), ReLU())\n",
    "        )\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(\n",
    "                Linear(dim_h, dim_h), nn.BatchNorm1d(dim_h), ReLU(), Linear(dim_h, dim_h), ReLU()\n",
    "            )\n",
    "        )\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(\n",
    "                Linear(dim_h, dim_h), nn.BatchNorm1d(dim_h), ReLU(), Linear(dim_h, dim_h), ReLU()\n",
    "            )\n",
    "        )\n",
    "        self.lin1 = Linear(dim_h, dim_h)\n",
    "        self.lin2 = Linear(dim_h, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        batch = data.batch\n",
    "\n",
    "        # Node embeddings\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv3(h, edge_index)\n",
    "\n",
    "        # Graph-level readout\n",
    "        h = gap(h, batch)\n",
    "\n",
    "        h = self.lin1(h)\n",
    "        h = h.relu()\n",
    "        h = self.dropout(h)\n",
    "        h = self.lin2(h)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "944a304d-e959-4c9b-8490-5d4d8013cc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GINConvNet(\n",
       "  (conv1): GINConv(nn=Sequential(\n",
       "    (0): Linear(in_features=9, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "  ))\n",
       "  (conv2): GINConv(nn=Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "  ))\n",
       "  (conv3): GINConv(nn=Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "  ))\n",
       "  (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_model1 = GINConvNet(input_dim=9, dim_h=128)\n",
    "g_model1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40484308-61b2-443f-9702-aab31017ca2e",
   "metadata": {},
   "source": [
    "## 3) 학습 및 평가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0652585-7ddd-470c-809c-629ed4bb4f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 진행 함수 정의\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def train(model, train_loader, valid_loader, epochs):\n",
    "    model = model.to(device)\n",
    "    # train_loader, valid_loader, test_loader = loaders\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr = 0.00001, momentum = 0.5) \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001) \n",
    "    criterion = nn.BCEWithLogitsLoss() \n",
    "\n",
    "    best_valid_loss = float('inf')  # 초기값을 무한대로 설정\n",
    "    best_epoch = 0  # 가장 성능 좋은 epoch을 기록\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        train_loss = 0.0\n",
    "        model.train() # 학습 모드 전환    \n",
    "\n",
    "        # train\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            y = data.y\n",
    "            \n",
    "            optimizer.zero_grad() # 전 단계에서의 loss gradient 값을 초기화\n",
    "            output = model(data)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        print(f\"Training Loss: {train_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # validation\n",
    "        model.eval() # 학습 모드 전환    \n",
    "        valid_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():  # Gradient 계산 비활성화\n",
    "            for data in valid_loader:\n",
    "                data = data.to(device)\n",
    "                y = data.y\n",
    "                \n",
    "                output = model(data)\n",
    "                loss = criterion(output, y)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "                # Accuracy 계산\n",
    "                predicted = (F.sigmoid(output) > 0.5).int()\n",
    "\n",
    "                total += y.size(0)\n",
    "                correct += (predicted == y).sum().item()\n",
    "\n",
    "        accuracy = 100 * (correct / total)\n",
    "        avg_valid_loss = valid_loss / len(valid_loader)\n",
    "        print(f\"Validation Loss: {avg_valid_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\\n\")\n",
    "        \n",
    "        # Best model 저장\n",
    "        if avg_valid_loss < best_valid_loss:\n",
    "            best_valid_loss = avg_valid_loss\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), \"best_epoch.pth\")\n",
    "            print(f\"Best model updated at epoch {best_epoch} with validation loss: {best_valid_loss:.4f}\")\n",
    "\n",
    "    print(f\"Training completed. Best model was at epoch {best_epoch} with validation loss: {best_valid_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3067ff-3017-4f75-8756-86f8aad88b96",
   "metadata": {},
   "source": [
    "- `model` : 학습할 데이터셋에 맞게 설정한 모델 입력\n",
    "- `train_loader`, `valid_loader` : 학습, 검증 data loader 입력\n",
    "- `epochs` : 반복할 학습 횟수 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "387bd47c-1401-4b66-b53e-f5c21f518b26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training Loss: 0.6828\n",
      "Validation Loss: 0.8653, Validation Accuracy: 13.91%\n",
      "\n",
      "Best model updated at epoch 1 with validation loss: 0.8653\n",
      "Epoch 2/10\n",
      "Training Loss: 0.5582\n",
      "Validation Loss: 0.9162, Validation Accuracy: 48.34%\n",
      "\n",
      "Epoch 3/10\n",
      "Training Loss: 0.4381\n",
      "Validation Loss: 0.6916, Validation Accuracy: 65.56%\n",
      "\n",
      "Best model updated at epoch 3 with validation loss: 0.6916\n",
      "Epoch 4/10\n",
      "Training Loss: 0.3413\n",
      "Validation Loss: 0.6377, Validation Accuracy: 60.93%\n",
      "\n",
      "Best model updated at epoch 4 with validation loss: 0.6377\n",
      "Epoch 5/10\n",
      "Training Loss: 0.2788\n",
      "Validation Loss: 1.0373, Validation Accuracy: 51.66%\n",
      "\n",
      "Epoch 6/10\n",
      "Training Loss: 0.2538\n",
      "Validation Loss: 0.9639, Validation Accuracy: 53.64%\n",
      "\n",
      "Epoch 7/10\n",
      "Training Loss: 0.2261\n",
      "Validation Loss: 0.8928, Validation Accuracy: 55.63%\n",
      "\n",
      "Epoch 8/10\n",
      "Training Loss: 0.1881\n",
      "Validation Loss: 0.7465, Validation Accuracy: 60.26%\n",
      "\n",
      "Epoch 9/10\n",
      "Training Loss: 0.1571\n",
      "Validation Loss: 0.9983, Validation Accuracy: 56.29%\n",
      "\n",
      "Epoch 10/10\n",
      "Training Loss: 0.1226\n",
      "Validation Loss: 1.1773, Validation Accuracy: 57.62%\n",
      "\n",
      "Training completed. Best model was at epoch 4 with validation loss: 0.6377\n"
     ]
    }
   ],
   "source": [
    "# fingerprint loader 생성\n",
    "train_loader, valid_loader, test_loader = get_dataloader(dataset_name = 'bace', data_type='Fingerprint', batch_size = 128)\n",
    "\n",
    "# 학습할 모델 정의\n",
    "fp_model1 = MLP(input_dim=1024, hidden_dim = 128, num_classes = 1, dropout_rate=0.2)\n",
    "\n",
    "# train\n",
    "p = train(fp_model1, train_loader, valid_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "773f3bf5-545f-453c-b737-3f10364b9995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Training Loss: 0.6813\n",
      "Validation Loss: 0.9569, Validation Accuracy: 13.91%\n",
      "\n",
      "Best model updated at epoch 1 with validation loss: 0.9569\n",
      "Epoch 2/50\n",
      "Training Loss: 0.6542\n",
      "Validation Loss: 0.9008, Validation Accuracy: 13.91%\n",
      "\n",
      "Best model updated at epoch 2 with validation loss: 0.9008\n",
      "Epoch 3/50\n",
      "Training Loss: 0.6061\n",
      "Validation Loss: 0.9626, Validation Accuracy: 32.45%\n",
      "\n",
      "Epoch 4/50\n",
      "Training Loss: 0.5361\n",
      "Validation Loss: 1.1104, Validation Accuracy: 45.70%\n",
      "\n",
      "Epoch 5/50\n",
      "Training Loss: 0.4948\n",
      "Validation Loss: 0.7691, Validation Accuracy: 66.89%\n",
      "\n",
      "Best model updated at epoch 5 with validation loss: 0.7691\n",
      "Epoch 6/50\n",
      "Training Loss: 0.4820\n",
      "Validation Loss: 0.7187, Validation Accuracy: 68.87%\n",
      "\n",
      "Best model updated at epoch 6 with validation loss: 0.7187\n",
      "Epoch 7/50\n",
      "Training Loss: 0.4548\n",
      "Validation Loss: 0.7487, Validation Accuracy: 66.23%\n",
      "\n",
      "Epoch 8/50\n",
      "Training Loss: 0.4291\n",
      "Validation Loss: 0.8553, Validation Accuracy: 64.24%\n",
      "\n",
      "Epoch 9/50\n",
      "Training Loss: 0.4111\n",
      "Validation Loss: 0.6007, Validation Accuracy: 74.17%\n",
      "\n",
      "Best model updated at epoch 9 with validation loss: 0.6007\n",
      "Epoch 10/50\n",
      "Training Loss: 0.4240\n",
      "Validation Loss: 0.6672, Validation Accuracy: 68.87%\n",
      "\n",
      "Epoch 11/50\n",
      "Training Loss: 0.3881\n",
      "Validation Loss: 0.8015, Validation Accuracy: 62.25%\n",
      "\n",
      "Epoch 12/50\n",
      "Training Loss: 0.3734\n",
      "Validation Loss: 0.5802, Validation Accuracy: 72.19%\n",
      "\n",
      "Best model updated at epoch 12 with validation loss: 0.5802\n",
      "Epoch 13/50\n",
      "Training Loss: 0.3631\n",
      "Validation Loss: 0.6287, Validation Accuracy: 66.89%\n",
      "\n",
      "Epoch 14/50\n",
      "Training Loss: 0.3677\n",
      "Validation Loss: 0.5147, Validation Accuracy: 74.83%\n",
      "\n",
      "Best model updated at epoch 14 with validation loss: 0.5147\n",
      "Epoch 15/50\n",
      "Training Loss: 0.3698\n",
      "Validation Loss: 0.4927, Validation Accuracy: 74.83%\n",
      "\n",
      "Best model updated at epoch 15 with validation loss: 0.4927\n",
      "Epoch 16/50\n",
      "Training Loss: 0.3722\n",
      "Validation Loss: 0.5527, Validation Accuracy: 72.19%\n",
      "\n",
      "Epoch 17/50\n",
      "Training Loss: 0.3605\n",
      "Validation Loss: 0.7192, Validation Accuracy: 64.24%\n",
      "\n",
      "Epoch 18/50\n",
      "Training Loss: 0.3384\n",
      "Validation Loss: 0.6900, Validation Accuracy: 62.25%\n",
      "\n",
      "Epoch 19/50\n",
      "Training Loss: 0.3173\n",
      "Validation Loss: 0.7642, Validation Accuracy: 59.60%\n",
      "\n",
      "Epoch 20/50\n",
      "Training Loss: 0.3209\n",
      "Validation Loss: 0.8314, Validation Accuracy: 58.94%\n",
      "\n",
      "Epoch 21/50\n",
      "Training Loss: 0.3145\n",
      "Validation Loss: 0.8143, Validation Accuracy: 60.93%\n",
      "\n",
      "Epoch 22/50\n",
      "Training Loss: 0.3110\n",
      "Validation Loss: 0.8270, Validation Accuracy: 59.60%\n",
      "\n",
      "Epoch 23/50\n",
      "Training Loss: 0.3123\n",
      "Validation Loss: 1.0720, Validation Accuracy: 51.66%\n",
      "\n",
      "Epoch 24/50\n",
      "Training Loss: 0.2980\n",
      "Validation Loss: 0.8271, Validation Accuracy: 60.93%\n",
      "\n",
      "Epoch 25/50\n",
      "Training Loss: 0.2970\n",
      "Validation Loss: 0.5667, Validation Accuracy: 69.54%\n",
      "\n",
      "Epoch 26/50\n",
      "Training Loss: 0.3031\n",
      "Validation Loss: 0.7750, Validation Accuracy: 64.90%\n",
      "\n",
      "Epoch 27/50\n",
      "Training Loss: 0.3019\n",
      "Validation Loss: 0.7901, Validation Accuracy: 58.94%\n",
      "\n",
      "Epoch 28/50\n",
      "Training Loss: 0.2947\n",
      "Validation Loss: 0.9309, Validation Accuracy: 58.28%\n",
      "\n",
      "Epoch 29/50\n",
      "Training Loss: 0.2894\n",
      "Validation Loss: 0.6550, Validation Accuracy: 66.23%\n",
      "\n",
      "Epoch 30/50\n",
      "Training Loss: 0.2858\n",
      "Validation Loss: 0.7615, Validation Accuracy: 65.56%\n",
      "\n",
      "Epoch 31/50\n",
      "Training Loss: 0.2723\n",
      "Validation Loss: 0.7403, Validation Accuracy: 66.89%\n",
      "\n",
      "Epoch 32/50\n",
      "Training Loss: 0.2657\n",
      "Validation Loss: 0.8150, Validation Accuracy: 60.93%\n",
      "\n",
      "Epoch 33/50\n",
      "Training Loss: 0.2523\n",
      "Validation Loss: 0.7032, Validation Accuracy: 66.89%\n",
      "\n",
      "Epoch 34/50\n",
      "Training Loss: 0.2649\n",
      "Validation Loss: 0.5284, Validation Accuracy: 75.50%\n",
      "\n",
      "Epoch 35/50\n",
      "Training Loss: 0.2553\n",
      "Validation Loss: 0.7134, Validation Accuracy: 68.21%\n",
      "\n",
      "Epoch 36/50\n",
      "Training Loss: 0.2585\n",
      "Validation Loss: 0.8604, Validation Accuracy: 62.25%\n",
      "\n",
      "Epoch 37/50\n",
      "Training Loss: 0.2666\n",
      "Validation Loss: 1.0592, Validation Accuracy: 54.97%\n",
      "\n",
      "Epoch 38/50\n",
      "Training Loss: 0.2538\n",
      "Validation Loss: 0.8506, Validation Accuracy: 62.25%\n",
      "\n",
      "Epoch 39/50\n",
      "Training Loss: 0.2565\n",
      "Validation Loss: 0.6731, Validation Accuracy: 67.55%\n",
      "\n",
      "Epoch 40/50\n",
      "Training Loss: 0.2474\n",
      "Validation Loss: 0.8757, Validation Accuracy: 61.59%\n",
      "\n",
      "Epoch 41/50\n",
      "Training Loss: 0.2409\n",
      "Validation Loss: 1.1531, Validation Accuracy: 46.36%\n",
      "\n",
      "Epoch 42/50\n",
      "Training Loss: 0.2801\n",
      "Validation Loss: 1.3786, Validation Accuracy: 41.06%\n",
      "\n",
      "Epoch 43/50\n",
      "Training Loss: 0.2800\n",
      "Validation Loss: 1.0036, Validation Accuracy: 52.32%\n",
      "\n",
      "Epoch 44/50\n",
      "Training Loss: 0.2395\n",
      "Validation Loss: 0.7028, Validation Accuracy: 66.23%\n",
      "\n",
      "Epoch 45/50\n",
      "Training Loss: 0.2453\n",
      "Validation Loss: 0.7907, Validation Accuracy: 62.25%\n",
      "\n",
      "Epoch 46/50\n",
      "Training Loss: 0.2294\n",
      "Validation Loss: 0.7654, Validation Accuracy: 64.24%\n",
      "\n",
      "Epoch 47/50\n",
      "Training Loss: 0.2333\n",
      "Validation Loss: 0.7992, Validation Accuracy: 61.59%\n",
      "\n",
      "Epoch 48/50\n",
      "Training Loss: 0.2425\n",
      "Validation Loss: 0.8323, Validation Accuracy: 61.59%\n",
      "\n",
      "Epoch 49/50\n",
      "Training Loss: 0.2358\n",
      "Validation Loss: 0.7447, Validation Accuracy: 67.55%\n",
      "\n",
      "Epoch 50/50\n",
      "Training Loss: 0.2161\n",
      "Validation Loss: 0.8017, Validation Accuracy: 68.87%\n",
      "\n",
      "Training completed. Best model was at epoch 15 with validation loss: 0.4927\n"
     ]
    }
   ],
   "source": [
    "# Descriptor loader 생성\n",
    "train_loader, valid_loader, test_loader = get_dataloader(dataset_name = 'bace', data_type='Descriptors', batch_size = 128)\n",
    "\n",
    "# 학습할 모델 정의\n",
    "ds_model = MLP(input_dim=210, hidden_dim = 128, num_classes = 1, dropout_rate=0.2)\n",
    "\n",
    "# train\n",
    "train(ds_model, train_loader, valid_loader, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bea4f062-3e79-45be-b9a2-84e1a70c3b0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training Loss: 0.6767\n",
      "Validation Loss: 0.8005, Validation Accuracy: 13.91%\n",
      "\n",
      "Best model updated at epoch 1 with validation loss: 0.8005\n",
      "Epoch 2/10\n",
      "Training Loss: 0.6638\n",
      "Validation Loss: 1.0546, Validation Accuracy: 13.91%\n",
      "\n",
      "Epoch 3/10\n",
      "Training Loss: 0.6584\n",
      "Validation Loss: 0.8463, Validation Accuracy: 13.91%\n",
      "\n",
      "Epoch 4/10\n",
      "Training Loss: 0.6280\n",
      "Validation Loss: 0.9499, Validation Accuracy: 13.91%\n",
      "\n",
      "Epoch 5/10\n",
      "Training Loss: 0.5714\n",
      "Validation Loss: 0.8492, Validation Accuracy: 54.30%\n",
      "\n",
      "Epoch 6/10\n",
      "Training Loss: 0.5368\n",
      "Validation Loss: 0.6796, Validation Accuracy: 78.81%\n",
      "\n",
      "Best model updated at epoch 6 with validation loss: 0.6796\n",
      "Epoch 7/10\n",
      "Training Loss: 0.5220\n",
      "Validation Loss: 1.0238, Validation Accuracy: 45.70%\n",
      "\n",
      "Epoch 8/10\n",
      "Training Loss: 0.4587\n",
      "Validation Loss: 0.6952, Validation Accuracy: 73.51%\n",
      "\n",
      "Epoch 9/10\n",
      "Training Loss: 0.4533\n",
      "Validation Loss: 0.6887, Validation Accuracy: 71.52%\n",
      "\n",
      "Epoch 10/10\n",
      "Training Loss: 0.4373\n",
      "Validation Loss: 0.7739, Validation Accuracy: 66.89%\n",
      "\n",
      "Training completed. Best model was at epoch 6 with validation loss: 0.6796\n"
     ]
    }
   ],
   "source": [
    "# Token loader 생성\n",
    "train_loader, valid_loader, test_loader = get_dataloader(dataset_name = 'bace', data_type='Token', batch_size = 128)\n",
    "\n",
    "# 학습할 모델 정의\n",
    "token_model = Conv1d(vocab_num=39, seq_len=178, emb_dim=64, hidden_size=32, kernel_size = 4, num_classes=1)\n",
    "\n",
    "# train\n",
    "train(token_model, train_loader, valid_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0cde6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training Loss: 0.8221\n",
      "Validation Loss: 2.1389, Validation Accuracy: 13.91%\n",
      "\n",
      "Best model updated at epoch 1 with validation loss: 2.1389\n",
      "Epoch 2/10\n",
      "Training Loss: 0.6059\n",
      "Validation Loss: 1.1479, Validation Accuracy: 25.17%\n",
      "\n",
      "Best model updated at epoch 2 with validation loss: 1.1479\n",
      "Epoch 3/10\n",
      "Training Loss: 0.5422\n",
      "Validation Loss: 0.8822, Validation Accuracy: 47.68%\n",
      "\n",
      "Best model updated at epoch 3 with validation loss: 0.8822\n",
      "Epoch 4/10\n",
      "Training Loss: 0.5047\n",
      "Validation Loss: 1.1775, Validation Accuracy: 37.75%\n",
      "\n",
      "Epoch 5/10\n",
      "Training Loss: 0.4846\n",
      "Validation Loss: 0.6652, Validation Accuracy: 57.62%\n",
      "\n",
      "Best model updated at epoch 5 with validation loss: 0.6652\n",
      "Epoch 6/10\n",
      "Training Loss: 0.4565\n",
      "Validation Loss: 1.1116, Validation Accuracy: 42.38%\n",
      "\n",
      "Epoch 7/10\n",
      "Training Loss: 0.4546\n",
      "Validation Loss: 2.0816, Validation Accuracy: 19.87%\n",
      "\n",
      "Epoch 8/10\n",
      "Training Loss: 0.4367\n",
      "Validation Loss: 1.0589, Validation Accuracy: 50.33%\n",
      "\n",
      "Epoch 9/10\n",
      "Training Loss: 0.4314\n",
      "Validation Loss: 0.3471, Validation Accuracy: 78.81%\n",
      "\n",
      "Best model updated at epoch 9 with validation loss: 0.3471\n",
      "Epoch 10/10\n",
      "Training Loss: 0.4196\n",
      "Validation Loss: 1.2913, Validation Accuracy: 42.38%\n",
      "\n",
      "Training completed. Best model was at epoch 9 with validation loss: 0.3471\n"
     ]
    }
   ],
   "source": [
    "# Graph loader 생성\n",
    "train_loader, valid_loader, test_loader = get_dataloader(dataset_name = 'bace', data_type='Graph', batch_size = 128)\n",
    "\n",
    "# 학습할 모델 정의\n",
    "g_model = GINConvNet(input_dim=9, dim_h=128)\n",
    "\n",
    "# train\n",
    "train(g_model, train_loader, valid_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe9646-036b-4d22-9f7c-98595a3c1c15",
   "metadata": {},
   "source": [
    "학습된 모델로 평가를 수행한다.\n",
    "\n",
    "평가는 accuracy, precision, recall, f1_score, roc_auc, average precision 총 6가지로 이루어지며, 설명은 다음과 같다.\n",
    "\n",
    "- Accuracy (정확도): 올바르게 예측한 샘플의 비율\n",
    "\n",
    "- Precision (정밀도): 모델이 양성으로 예측한 샘플 중 실제로 양성인 비율.\n",
    "\n",
    "- Recall (재현율): 실제 양성 샘플 중 모델이 양성으로 예측한 비율.\n",
    "\n",
    "- F1-Score: Precision과 Recall의 조화 평균.데이터가 불균형할 때 모델의 전반적 성능을 파악하기 좋음.\n",
    "\n",
    "- AUC_ROC (ROC 곡선 아래 면적): 민감도(TPR)와 특이도(1-FPR) 간의 균형을 평가.1에 가까울수록 좋음.\n",
    "\n",
    "- AUC_PRC (PRC 곡선 아래 면적): Precision과 Recall 간의 관계를 시각화한 곡선의 면적."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ce32eb5-064b-46dc-9415-a27b9cbf5c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, save_file = 'Results.csv'):\n",
    "    model = model.to(device)\n",
    "    model.eval()    \n",
    "    criterion = nn.BCEWithLogitsLoss() \n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():  # Gradient 계산 비활성화\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            y = data.y\n",
    "            \n",
    "            output = model(data)\n",
    "            preds = torch.sigmoid(output).cpu().numpy().ravel()  # Sigmoid로 확률 변환 후 numpy로 변환\n",
    "            all_preds.append(preds)\n",
    "            all_targets.append(y.cpu().numpy())\n",
    "            \n",
    "            # 손실 계산\n",
    "            test_loss += criterion(output, y).item()\n",
    "            \n",
    "        # Concatenate predictions and targets\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_targets = np.concatenate(all_targets).astype(int)\n",
    "    \n",
    "        # 메트릭 계산\n",
    "        test_acc = accuracy_score(all_targets, (all_preds >= 0.5).astype(int))\n",
    "        test_precision = precision_score(all_targets, (all_preds >= 0.5).astype(int))\n",
    "        test_recall = recall_score(all_targets, (all_preds >= 0.5).astype(int))\n",
    "        test_f1 = f1_score(all_targets, (all_preds >= 0.5).astype(int))\n",
    "        test_auc_roc = roc_auc_score(all_targets, all_preds)\n",
    "        test_auc_prc = average_precision_score(all_targets, all_preds)\n",
    "    \n",
    "        # 평균 손실 계산\n",
    "        test_loss /= len(test_loader)\n",
    "    \n",
    "        # 결과 저장\n",
    "        metrics = {\n",
    "            \"Loss\": test_loss,\n",
    "            \"Accuracy\": test_acc,\n",
    "            \"Precision\": test_precision,\n",
    "            \"Recall\": test_recall,\n",
    "            \"F1-Score\": test_f1,\n",
    "            \"AUC_ROC\": test_auc_roc,\n",
    "            \"AUC_PRC\": test_auc_prc\n",
    "        }\n",
    "    \n",
    "        # 결과 출력\n",
    "        print(\"\\n최적 모델의 테스트 데이터 성능:\")\n",
    "        print(tabulate(pd.DataFrame(metrics, index=[\"Metric Value\"]).T, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "    \n",
    "        # CSV 파일 저장\n",
    "        df = pd.DataFrame(metrics, index=[0])\n",
    "        df.to_csv(save_file, index=False)\n",
    "        print(f\"\\nResults saved to {save_file}\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90bdbc98-1602-4828-8095-72f029622c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최적 모델의 테스트 데이터 성능:\n",
      "╒═══════════╤════════════════╕\n",
      "│           │   Metric Value │\n",
      "╞═══════════╪════════════════╡\n",
      "│ Loss      │       0.400567 │\n",
      "├───────────┼────────────────┤\n",
      "│ Accuracy  │       0.789474 │\n",
      "├───────────┼────────────────┤\n",
      "│ Precision │       0.742574 │\n",
      "├───────────┼────────────────┤\n",
      "│ Recall    │       0.925926 │\n",
      "├───────────┼────────────────┤\n",
      "│ F1-Score  │       0.824176 │\n",
      "├───────────┼────────────────┤\n",
      "│ AUC_ROC   │       0.841071 │\n",
      "├───────────┼────────────────┤\n",
      "│ AUC_PRC   │       0.819085 │\n",
      "╘═══════════╧════════════════╛\n",
      "\n",
      "Results saved to Results.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Loss': 0.4005669206380844,\n",
       " 'Accuracy': 0.7894736842105263,\n",
       " 'Precision': 0.7425742574257426,\n",
       " 'Recall': 0.9259259259259259,\n",
       " 'F1-Score': 0.8241758241758241,\n",
       " 'AUC_ROC': 0.8410711180664232,\n",
       " 'AUC_PRC': 0.8190849653900989}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best model load\n",
    "g_model = GINConvNet(input_dim=9, dim_h=128)\n",
    "g_model.load_state_dict(torch.load(\"best_epoch.pth\"))\n",
    "test(g_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4212ae31",
   "metadata": {},
   "source": [
    "### ESOL 데이터로 Regression 예측 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f859e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def train_reg(model, train_loader, valid_loader, epochs):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_valid_rmse = float('inf')  # RMSE 기준으로 변경\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            y = data.y\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_rmse = np.sqrt(avg_train_loss)  # MSE를 RMSE로 변환\n",
    "        print(f\"Training RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data in valid_loader:\n",
    "                data = data.to(device)\n",
    "                y = data.y\n",
    "                \n",
    "                output = model(data)\n",
    "                loss = criterion(output, y)\n",
    "                valid_loss += loss.item()\n",
    "                \n",
    "                # Store predictions and targets\n",
    "                all_preds.extend(output.cpu().numpy())\n",
    "                all_targets.extend(y.cpu().numpy())\n",
    "\n",
    "        # Calculate metrics\n",
    "        avg_valid_loss = valid_loss / len(valid_loader)\n",
    "        valid_rmse = np.sqrt(avg_valid_loss)  # MSE를 RMSE로 변환\n",
    "        r2 = r2_score(all_targets, all_preds)\n",
    "        \n",
    "        print(f\"Validation RMSE: {valid_rmse:.4f}, R2 Score: {r2:.4f}\\n\")\n",
    "        \n",
    "        # Save best model (RMSE 기준으로 변경)\n",
    "        if valid_rmse < best_valid_rmse:\n",
    "            best_valid_rmse = valid_rmse\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), \"best_epoch.pth\")\n",
    "            print(f\"Best model updated at epoch {best_epoch} with validation RMSE: {best_valid_rmse:.4f}\")\n",
    "\n",
    "    print(f\"Training completed. Best model was at epoch {best_epoch} with validation RMSE: {best_valid_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22e9ae5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Training RMSE: 3.5534\n",
      "Validation RMSE: 3.2482, R2 Score: -1.3439\n",
      "\n",
      "Best model updated at epoch 1 with validation RMSE: 3.2482\n",
      "Epoch 2/100\n",
      "Training RMSE: 2.8071\n",
      "Validation RMSE: 2.1644, R2 Score: -0.0407\n",
      "\n",
      "Best model updated at epoch 2 with validation RMSE: 2.1644\n",
      "Epoch 3/100\n",
      "Training RMSE: 2.0501\n",
      "Validation RMSE: 1.7339, R2 Score: 0.3321\n",
      "\n",
      "Best model updated at epoch 3 with validation RMSE: 1.7339\n",
      "Epoch 4/100\n",
      "Training RMSE: 1.7549\n",
      "Validation RMSE: 1.5802, R2 Score: 0.4453\n",
      "\n",
      "Best model updated at epoch 4 with validation RMSE: 1.5802\n",
      "Epoch 5/100\n",
      "Training RMSE: 1.4476\n",
      "Validation RMSE: 1.3852, R2 Score: 0.5737\n",
      "\n",
      "Best model updated at epoch 5 with validation RMSE: 1.3852\n",
      "Epoch 6/100\n",
      "Training RMSE: 1.4015\n",
      "Validation RMSE: 1.2666, R2 Score: 0.6436\n",
      "\n",
      "Best model updated at epoch 6 with validation RMSE: 1.2666\n",
      "Epoch 7/100\n",
      "Training RMSE: 1.3221\n",
      "Validation RMSE: 1.1993, R2 Score: 0.6805\n",
      "\n",
      "Best model updated at epoch 7 with validation RMSE: 1.1993\n",
      "Epoch 8/100\n",
      "Training RMSE: 1.0920\n",
      "Validation RMSE: 1.1477, R2 Score: 0.7074\n",
      "\n",
      "Best model updated at epoch 8 with validation RMSE: 1.1477\n",
      "Epoch 9/100\n",
      "Training RMSE: 1.0271\n",
      "Validation RMSE: 1.1166, R2 Score: 0.7230\n",
      "\n",
      "Best model updated at epoch 9 with validation RMSE: 1.1166\n",
      "Epoch 10/100\n",
      "Training RMSE: 1.0583\n",
      "Validation RMSE: 1.1034, R2 Score: 0.7295\n",
      "\n",
      "Best model updated at epoch 10 with validation RMSE: 1.1034\n",
      "Epoch 11/100\n",
      "Training RMSE: 0.9662\n",
      "Validation RMSE: 1.0819, R2 Score: 0.7400\n",
      "\n",
      "Best model updated at epoch 11 with validation RMSE: 1.0819\n",
      "Epoch 12/100\n",
      "Training RMSE: 1.1362\n",
      "Validation RMSE: 1.0610, R2 Score: 0.7499\n",
      "\n",
      "Best model updated at epoch 12 with validation RMSE: 1.0610\n",
      "Epoch 13/100\n",
      "Training RMSE: 0.8778\n",
      "Validation RMSE: 1.0465, R2 Score: 0.7567\n",
      "\n",
      "Best model updated at epoch 13 with validation RMSE: 1.0465\n",
      "Epoch 14/100\n",
      "Training RMSE: 0.8930\n",
      "Validation RMSE: 1.0317, R2 Score: 0.7635\n",
      "\n",
      "Best model updated at epoch 14 with validation RMSE: 1.0317\n",
      "Epoch 15/100\n",
      "Training RMSE: 0.7947\n",
      "Validation RMSE: 1.0241, R2 Score: 0.7670\n",
      "\n",
      "Best model updated at epoch 15 with validation RMSE: 1.0241\n",
      "Epoch 16/100\n",
      "Training RMSE: 0.7660\n",
      "Validation RMSE: 1.0297, R2 Score: 0.7645\n",
      "\n",
      "Epoch 17/100\n",
      "Training RMSE: 0.7859\n",
      "Validation RMSE: 0.9963, R2 Score: 0.7795\n",
      "\n",
      "Best model updated at epoch 17 with validation RMSE: 0.9963\n",
      "Epoch 18/100\n",
      "Training RMSE: 0.6886\n",
      "Validation RMSE: 1.0058, R2 Score: 0.7752\n",
      "\n",
      "Epoch 19/100\n",
      "Training RMSE: 0.7786\n",
      "Validation RMSE: 0.9886, R2 Score: 0.7829\n",
      "\n",
      "Best model updated at epoch 19 with validation RMSE: 0.9886\n",
      "Epoch 20/100\n",
      "Training RMSE: 0.6901\n",
      "Validation RMSE: 0.9916, R2 Score: 0.7816\n",
      "\n",
      "Epoch 21/100\n",
      "Training RMSE: 0.7006\n",
      "Validation RMSE: 0.9670, R2 Score: 0.7923\n",
      "\n",
      "Best model updated at epoch 21 with validation RMSE: 0.9670\n",
      "Epoch 22/100\n",
      "Training RMSE: 0.6584\n",
      "Validation RMSE: 0.9460, R2 Score: 0.8012\n",
      "\n",
      "Best model updated at epoch 22 with validation RMSE: 0.9460\n",
      "Epoch 23/100\n",
      "Training RMSE: 0.6693\n",
      "Validation RMSE: 1.0055, R2 Score: 0.7754\n",
      "\n",
      "Epoch 24/100\n",
      "Training RMSE: 0.7235\n",
      "Validation RMSE: 0.9725, R2 Score: 0.7899\n",
      "\n",
      "Epoch 25/100\n",
      "Training RMSE: 0.7467\n",
      "Validation RMSE: 0.9642, R2 Score: 0.7935\n",
      "\n",
      "Epoch 26/100\n",
      "Training RMSE: 0.7444\n",
      "Validation RMSE: 0.9435, R2 Score: 0.8023\n",
      "\n",
      "Best model updated at epoch 26 with validation RMSE: 0.9435\n",
      "Epoch 27/100\n",
      "Training RMSE: 0.6320\n",
      "Validation RMSE: 0.9640, R2 Score: 0.7936\n",
      "\n",
      "Epoch 28/100\n",
      "Training RMSE: 0.5909\n",
      "Validation RMSE: 0.9516, R2 Score: 0.7988\n",
      "\n",
      "Epoch 29/100\n",
      "Training RMSE: 0.6162\n",
      "Validation RMSE: 0.9431, R2 Score: 0.8024\n",
      "\n",
      "Best model updated at epoch 29 with validation RMSE: 0.9431\n",
      "Epoch 30/100\n",
      "Training RMSE: 0.5801\n",
      "Validation RMSE: 0.9180, R2 Score: 0.8128\n",
      "\n",
      "Best model updated at epoch 30 with validation RMSE: 0.9180\n",
      "Epoch 31/100\n",
      "Training RMSE: 0.6013\n",
      "Validation RMSE: 0.9373, R2 Score: 0.8048\n",
      "\n",
      "Epoch 32/100\n",
      "Training RMSE: 0.5540\n",
      "Validation RMSE: 0.9478, R2 Score: 0.8004\n",
      "\n",
      "Epoch 33/100\n",
      "Training RMSE: 0.6064\n",
      "Validation RMSE: 0.9473, R2 Score: 0.8006\n",
      "\n",
      "Epoch 34/100\n",
      "Training RMSE: 0.5486\n",
      "Validation RMSE: 0.9366, R2 Score: 0.8051\n",
      "\n",
      "Epoch 35/100\n",
      "Training RMSE: 0.5512\n",
      "Validation RMSE: 0.9256, R2 Score: 0.8097\n",
      "\n",
      "Epoch 36/100\n",
      "Training RMSE: 0.5782\n",
      "Validation RMSE: 0.9476, R2 Score: 0.8005\n",
      "\n",
      "Epoch 37/100\n",
      "Training RMSE: 0.5389\n",
      "Validation RMSE: 0.9903, R2 Score: 0.7821\n",
      "\n",
      "Epoch 38/100\n",
      "Training RMSE: 0.5715\n",
      "Validation RMSE: 0.9602, R2 Score: 0.7952\n",
      "\n",
      "Epoch 39/100\n",
      "Training RMSE: 0.6121\n",
      "Validation RMSE: 0.9636, R2 Score: 0.7937\n",
      "\n",
      "Epoch 40/100\n",
      "Training RMSE: 0.5535\n",
      "Validation RMSE: 0.9809, R2 Score: 0.7863\n",
      "\n",
      "Epoch 41/100\n",
      "Training RMSE: 0.5527\n",
      "Validation RMSE: 0.9869, R2 Score: 0.7836\n",
      "\n",
      "Epoch 42/100\n",
      "Training RMSE: 0.5357\n",
      "Validation RMSE: 0.9875, R2 Score: 0.7834\n",
      "\n",
      "Epoch 43/100\n",
      "Training RMSE: 0.5534\n",
      "Validation RMSE: 0.9637, R2 Score: 0.7937\n",
      "\n",
      "Epoch 44/100\n",
      "Training RMSE: 0.5494\n",
      "Validation RMSE: 0.9721, R2 Score: 0.7901\n",
      "\n",
      "Epoch 45/100\n",
      "Training RMSE: 0.6377\n",
      "Validation RMSE: 1.0062, R2 Score: 0.7751\n",
      "\n",
      "Epoch 46/100\n",
      "Training RMSE: 0.6619\n",
      "Validation RMSE: 1.0871, R2 Score: 0.7374\n",
      "\n",
      "Epoch 47/100\n",
      "Training RMSE: 0.5748\n",
      "Validation RMSE: 1.0798, R2 Score: 0.7410\n",
      "\n",
      "Epoch 48/100\n",
      "Training RMSE: 0.5573\n",
      "Validation RMSE: 1.0385, R2 Score: 0.7604\n",
      "\n",
      "Epoch 49/100\n",
      "Training RMSE: 0.5505\n",
      "Validation RMSE: 1.0026, R2 Score: 0.7767\n",
      "\n",
      "Epoch 50/100\n",
      "Training RMSE: 0.5375\n",
      "Validation RMSE: 0.9864, R2 Score: 0.7838\n",
      "\n",
      "Epoch 51/100\n",
      "Training RMSE: 0.5294\n",
      "Validation RMSE: 1.0341, R2 Score: 0.7624\n",
      "\n",
      "Epoch 52/100\n",
      "Training RMSE: 0.8912\n",
      "Validation RMSE: 1.0372, R2 Score: 0.7610\n",
      "\n",
      "Epoch 53/100\n",
      "Training RMSE: 0.5984\n",
      "Validation RMSE: 1.0278, R2 Score: 0.7653\n",
      "\n",
      "Epoch 54/100\n",
      "Training RMSE: 0.5422\n",
      "Validation RMSE: 0.9489, R2 Score: 0.8000\n",
      "\n",
      "Epoch 55/100\n",
      "Training RMSE: 0.5681\n",
      "Validation RMSE: 0.9449, R2 Score: 0.8017\n",
      "\n",
      "Epoch 56/100\n",
      "Training RMSE: 0.5402\n",
      "Validation RMSE: 0.9484, R2 Score: 0.8002\n",
      "\n",
      "Epoch 57/100\n",
      "Training RMSE: 0.5223\n",
      "Validation RMSE: 0.9634, R2 Score: 0.7938\n",
      "\n",
      "Epoch 58/100\n",
      "Training RMSE: 0.5755\n",
      "Validation RMSE: 0.9809, R2 Score: 0.7863\n",
      "\n",
      "Epoch 59/100\n",
      "Training RMSE: 0.4994\n",
      "Validation RMSE: 0.9570, R2 Score: 0.7965\n",
      "\n",
      "Epoch 60/100\n",
      "Training RMSE: 0.5189\n",
      "Validation RMSE: 0.9491, R2 Score: 0.7999\n",
      "\n",
      "Epoch 61/100\n",
      "Training RMSE: 0.5096\n",
      "Validation RMSE: 0.9577, R2 Score: 0.7962\n",
      "\n",
      "Epoch 62/100\n",
      "Training RMSE: 0.5213\n",
      "Validation RMSE: 0.9809, R2 Score: 0.7862\n",
      "\n",
      "Epoch 63/100\n",
      "Training RMSE: 0.5098\n",
      "Validation RMSE: 0.9616, R2 Score: 0.7946\n",
      "\n",
      "Epoch 64/100\n",
      "Training RMSE: 0.6093\n",
      "Validation RMSE: 0.9592, R2 Score: 0.7956\n",
      "\n",
      "Epoch 65/100\n",
      "Training RMSE: 0.5250\n",
      "Validation RMSE: 0.9651, R2 Score: 0.7931\n",
      "\n",
      "Epoch 66/100\n",
      "Training RMSE: 0.5350\n",
      "Validation RMSE: 0.9691, R2 Score: 0.7914\n",
      "\n",
      "Epoch 67/100\n",
      "Training RMSE: 0.5427\n",
      "Validation RMSE: 0.9690, R2 Score: 0.7914\n",
      "\n",
      "Epoch 68/100\n",
      "Training RMSE: 0.6207\n",
      "Validation RMSE: 0.9740, R2 Score: 0.7892\n",
      "\n",
      "Epoch 69/100\n",
      "Training RMSE: 0.5396\n",
      "Validation RMSE: 0.9865, R2 Score: 0.7838\n",
      "\n",
      "Epoch 70/100\n",
      "Training RMSE: 0.5261\n",
      "Validation RMSE: 0.9390, R2 Score: 0.8041\n",
      "\n",
      "Epoch 71/100\n",
      "Training RMSE: 0.5478\n",
      "Validation RMSE: 0.9559, R2 Score: 0.7970\n",
      "\n",
      "Epoch 72/100\n",
      "Training RMSE: 0.4933\n",
      "Validation RMSE: 0.9706, R2 Score: 0.7907\n",
      "\n",
      "Epoch 73/100\n",
      "Training RMSE: 0.6157\n",
      "Validation RMSE: 0.9735, R2 Score: 0.7895\n",
      "\n",
      "Epoch 74/100\n",
      "Training RMSE: 0.5397\n",
      "Validation RMSE: 0.9125, R2 Score: 0.8150\n",
      "\n",
      "Best model updated at epoch 74 with validation RMSE: 0.9125\n",
      "Epoch 75/100\n",
      "Training RMSE: 0.5198\n",
      "Validation RMSE: 0.9216, R2 Score: 0.8113\n",
      "\n",
      "Epoch 76/100\n",
      "Training RMSE: 0.4874\n",
      "Validation RMSE: 0.9725, R2 Score: 0.7899\n",
      "\n",
      "Epoch 77/100\n",
      "Training RMSE: 0.5118\n",
      "Validation RMSE: 0.9534, R2 Score: 0.7981\n",
      "\n",
      "Epoch 78/100\n",
      "Training RMSE: 0.5155\n",
      "Validation RMSE: 0.9350, R2 Score: 0.8058\n",
      "\n",
      "Epoch 79/100\n",
      "Training RMSE: 0.5591\n",
      "Validation RMSE: 0.9478, R2 Score: 0.8004\n",
      "\n",
      "Epoch 80/100\n",
      "Training RMSE: 0.5454\n",
      "Validation RMSE: 0.9953, R2 Score: 0.7799\n",
      "\n",
      "Epoch 81/100\n",
      "Training RMSE: 0.5398\n",
      "Validation RMSE: 0.9911, R2 Score: 0.7818\n",
      "\n",
      "Epoch 82/100\n",
      "Training RMSE: 0.5179\n",
      "Validation RMSE: 0.9751, R2 Score: 0.7888\n",
      "\n",
      "Epoch 83/100\n",
      "Training RMSE: 0.4997\n",
      "Validation RMSE: 0.9416, R2 Score: 0.8030\n",
      "\n",
      "Epoch 84/100\n",
      "Training RMSE: 0.4865\n",
      "Validation RMSE: 0.9475, R2 Score: 0.8006\n",
      "\n",
      "Epoch 85/100\n",
      "Training RMSE: 0.4969\n",
      "Validation RMSE: 0.9400, R2 Score: 0.8037\n",
      "\n",
      "Epoch 86/100\n",
      "Training RMSE: 0.5253\n",
      "Validation RMSE: 0.9463, R2 Score: 0.8011\n",
      "\n",
      "Epoch 87/100\n",
      "Training RMSE: 0.4993\n",
      "Validation RMSE: 0.9444, R2 Score: 0.8019\n",
      "\n",
      "Epoch 88/100\n",
      "Training RMSE: 0.6614\n",
      "Validation RMSE: 0.9462, R2 Score: 0.8011\n",
      "\n",
      "Epoch 89/100\n",
      "Training RMSE: 0.5265\n",
      "Validation RMSE: 0.9391, R2 Score: 0.8041\n",
      "\n",
      "Epoch 90/100\n",
      "Training RMSE: 0.5281\n",
      "Validation RMSE: 0.9474, R2 Score: 0.8006\n",
      "\n",
      "Epoch 91/100\n",
      "Training RMSE: 0.7283\n",
      "Validation RMSE: 0.9634, R2 Score: 0.7938\n",
      "\n",
      "Epoch 92/100\n",
      "Training RMSE: 0.5590\n",
      "Validation RMSE: 1.0650, R2 Score: 0.7480\n",
      "\n",
      "Epoch 93/100\n",
      "Training RMSE: 0.5345\n",
      "Validation RMSE: 0.9976, R2 Score: 0.7789\n",
      "\n",
      "Epoch 94/100\n",
      "Training RMSE: 0.4965\n",
      "Validation RMSE: 0.9693, R2 Score: 0.7913\n",
      "\n",
      "Epoch 95/100\n",
      "Training RMSE: 0.4919\n",
      "Validation RMSE: 0.9537, R2 Score: 0.7979\n",
      "\n",
      "Epoch 96/100\n",
      "Training RMSE: 0.4937\n",
      "Validation RMSE: 0.9620, R2 Score: 0.7944\n",
      "\n",
      "Epoch 97/100\n",
      "Training RMSE: 0.4664\n",
      "Validation RMSE: 0.9632, R2 Score: 0.7939\n",
      "\n",
      "Epoch 98/100\n",
      "Training RMSE: 0.5145\n",
      "Validation RMSE: 0.9377, R2 Score: 0.8047\n",
      "\n",
      "Epoch 99/100\n",
      "Training RMSE: 0.4533\n",
      "Validation RMSE: 0.9536, R2 Score: 0.7980\n",
      "\n",
      "Epoch 100/100\n",
      "Training RMSE: 0.4915\n",
      "Validation RMSE: 0.9477, R2 Score: 0.8005\n",
      "\n",
      "Training completed. Best model was at epoch 74 with validation RMSE: 0.9125\n"
     ]
    }
   ],
   "source": [
    "# Graph loader 생성\n",
    "train_loader, valid_loader, test_loader = get_dataloader(dataset_name = 'esol', data_type='Fingerprint', batch_size = 128)\n",
    "\n",
    "# 학습할 모델 정의\n",
    "fp_reg_model = MLP(input_dim=1024, hidden_dim = 128, num_classes = 1, dropout_rate=0.2)\n",
    "\n",
    "# train\n",
    "train_reg(fp_reg_model, train_loader, valid_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d51874b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Training RMSE: 3.7181\n",
      "Validation RMSE: 3.0301, R2 Score: -1.0397\n",
      "\n",
      "Best model updated at epoch 1 with validation RMSE: 3.0301\n",
      "Epoch 2/100\n",
      "Training RMSE: 2.4356\n",
      "Validation RMSE: 2.0624, R2 Score: 0.0551\n",
      "\n",
      "Best model updated at epoch 2 with validation RMSE: 2.0624\n",
      "Epoch 3/100\n",
      "Training RMSE: 1.8898\n",
      "Validation RMSE: 1.7615, R2 Score: 0.3107\n",
      "\n",
      "Best model updated at epoch 3 with validation RMSE: 1.7615\n",
      "Epoch 4/100\n",
      "Training RMSE: 1.7656\n",
      "Validation RMSE: 1.4981, R2 Score: 0.5014\n",
      "\n",
      "Best model updated at epoch 4 with validation RMSE: 1.4981\n",
      "Epoch 5/100\n",
      "Training RMSE: 1.5916\n",
      "Validation RMSE: 1.2780, R2 Score: 0.6371\n",
      "\n",
      "Best model updated at epoch 5 with validation RMSE: 1.2780\n",
      "Epoch 6/100\n",
      "Training RMSE: 1.4643\n",
      "Validation RMSE: 1.0944, R2 Score: 0.7339\n",
      "\n",
      "Best model updated at epoch 6 with validation RMSE: 1.0944\n",
      "Epoch 7/100\n",
      "Training RMSE: 1.1111\n",
      "Validation RMSE: 0.9754, R2 Score: 0.7886\n",
      "\n",
      "Best model updated at epoch 7 with validation RMSE: 0.9754\n",
      "Epoch 8/100\n",
      "Training RMSE: 1.0893\n",
      "Validation RMSE: 0.9103, R2 Score: 0.8159\n",
      "\n",
      "Best model updated at epoch 8 with validation RMSE: 0.9103\n",
      "Epoch 9/100\n",
      "Training RMSE: 0.9490\n",
      "Validation RMSE: 0.8501, R2 Score: 0.8395\n",
      "\n",
      "Best model updated at epoch 9 with validation RMSE: 0.8501\n",
      "Epoch 10/100\n",
      "Training RMSE: 0.8899\n",
      "Validation RMSE: 0.7804, R2 Score: 0.8647\n",
      "\n",
      "Best model updated at epoch 10 with validation RMSE: 0.7804\n",
      "Epoch 11/100\n",
      "Training RMSE: 0.8598\n",
      "Validation RMSE: 0.7404, R2 Score: 0.8782\n",
      "\n",
      "Best model updated at epoch 11 with validation RMSE: 0.7404\n",
      "Epoch 12/100\n",
      "Training RMSE: 0.8961\n",
      "Validation RMSE: 0.7485, R2 Score: 0.8755\n",
      "\n",
      "Epoch 13/100\n",
      "Training RMSE: 0.8203\n",
      "Validation RMSE: 0.6768, R2 Score: 0.8982\n",
      "\n",
      "Best model updated at epoch 13 with validation RMSE: 0.6768\n",
      "Epoch 14/100\n",
      "Training RMSE: 0.8945\n",
      "Validation RMSE: 0.7001, R2 Score: 0.8911\n",
      "\n",
      "Epoch 15/100\n",
      "Training RMSE: 0.8527\n",
      "Validation RMSE: 0.7599, R2 Score: 0.8717\n",
      "\n",
      "Epoch 16/100\n",
      "Training RMSE: 0.8368\n",
      "Validation RMSE: 0.6757, R2 Score: 0.8986\n",
      "\n",
      "Best model updated at epoch 16 with validation RMSE: 0.6757\n",
      "Epoch 17/100\n",
      "Training RMSE: 0.7827\n",
      "Validation RMSE: 0.6369, R2 Score: 0.9099\n",
      "\n",
      "Best model updated at epoch 17 with validation RMSE: 0.6369\n",
      "Epoch 18/100\n",
      "Training RMSE: 0.8005\n",
      "Validation RMSE: 0.6611, R2 Score: 0.9029\n",
      "\n",
      "Epoch 19/100\n",
      "Training RMSE: 0.7788\n",
      "Validation RMSE: 0.6501, R2 Score: 0.9061\n",
      "\n",
      "Epoch 20/100\n",
      "Training RMSE: 0.7448\n",
      "Validation RMSE: 0.6270, R2 Score: 0.9127\n",
      "\n",
      "Best model updated at epoch 20 with validation RMSE: 0.6270\n",
      "Epoch 21/100\n",
      "Training RMSE: 0.7855\n",
      "Validation RMSE: 0.6297, R2 Score: 0.9119\n",
      "\n",
      "Epoch 22/100\n",
      "Training RMSE: 0.7650\n",
      "Validation RMSE: 0.6231, R2 Score: 0.9138\n",
      "\n",
      "Best model updated at epoch 22 with validation RMSE: 0.6231\n",
      "Epoch 23/100\n",
      "Training RMSE: 0.7626\n",
      "Validation RMSE: 0.6284, R2 Score: 0.9123\n",
      "\n",
      "Epoch 24/100\n",
      "Training RMSE: 0.7046\n",
      "Validation RMSE: 0.6168, R2 Score: 0.9155\n",
      "\n",
      "Best model updated at epoch 24 with validation RMSE: 0.6168\n",
      "Epoch 25/100\n",
      "Training RMSE: 0.7200\n",
      "Validation RMSE: 0.5951, R2 Score: 0.9213\n",
      "\n",
      "Best model updated at epoch 25 with validation RMSE: 0.5951\n",
      "Epoch 26/100\n",
      "Training RMSE: 0.7264\n",
      "Validation RMSE: 0.6181, R2 Score: 0.9151\n",
      "\n",
      "Epoch 27/100\n",
      "Training RMSE: 0.7674\n",
      "Validation RMSE: 0.5783, R2 Score: 0.9257\n",
      "\n",
      "Best model updated at epoch 27 with validation RMSE: 0.5783\n",
      "Epoch 28/100\n",
      "Training RMSE: 0.7246\n",
      "Validation RMSE: 0.5875, R2 Score: 0.9233\n",
      "\n",
      "Epoch 29/100\n",
      "Training RMSE: 0.8328\n",
      "Validation RMSE: 0.7441, R2 Score: 0.8770\n",
      "\n",
      "Epoch 30/100\n",
      "Training RMSE: 0.8088\n",
      "Validation RMSE: 0.6458, R2 Score: 0.9073\n",
      "\n",
      "Epoch 31/100\n",
      "Training RMSE: 0.7245\n",
      "Validation RMSE: 0.5789, R2 Score: 0.9255\n",
      "\n",
      "Epoch 32/100\n",
      "Training RMSE: 0.7040\n",
      "Validation RMSE: 0.5866, R2 Score: 0.9236\n",
      "\n",
      "Epoch 33/100\n",
      "Training RMSE: 0.6939\n",
      "Validation RMSE: 0.5826, R2 Score: 0.9246\n",
      "\n",
      "Epoch 34/100\n",
      "Training RMSE: 0.7558\n",
      "Validation RMSE: 0.5675, R2 Score: 0.9284\n",
      "\n",
      "Best model updated at epoch 34 with validation RMSE: 0.5675\n",
      "Epoch 35/100\n",
      "Training RMSE: 0.6505\n",
      "Validation RMSE: 0.5613, R2 Score: 0.9300\n",
      "\n",
      "Best model updated at epoch 35 with validation RMSE: 0.5613\n",
      "Epoch 36/100\n",
      "Training RMSE: 0.7115\n",
      "Validation RMSE: 0.5835, R2 Score: 0.9244\n",
      "\n",
      "Epoch 37/100\n",
      "Training RMSE: 0.6715\n",
      "Validation RMSE: 0.5709, R2 Score: 0.9276\n",
      "\n",
      "Epoch 38/100\n",
      "Training RMSE: 0.7363\n",
      "Validation RMSE: 0.5818, R2 Score: 0.9248\n",
      "\n",
      "Epoch 39/100\n",
      "Training RMSE: 0.6873\n",
      "Validation RMSE: 0.5475, R2 Score: 0.9334\n",
      "\n",
      "Best model updated at epoch 39 with validation RMSE: 0.5475\n",
      "Epoch 40/100\n",
      "Training RMSE: 0.7176\n",
      "Validation RMSE: 0.5423, R2 Score: 0.9347\n",
      "\n",
      "Best model updated at epoch 40 with validation RMSE: 0.5423\n",
      "Epoch 41/100\n",
      "Training RMSE: 0.7717\n",
      "Validation RMSE: 0.6177, R2 Score: 0.9152\n",
      "\n",
      "Epoch 42/100\n",
      "Training RMSE: 0.7279\n",
      "Validation RMSE: 0.7328, R2 Score: 0.8807\n",
      "\n",
      "Epoch 43/100\n",
      "Training RMSE: 0.8003\n",
      "Validation RMSE: 0.5627, R2 Score: 0.9297\n",
      "\n",
      "Epoch 44/100\n",
      "Training RMSE: 0.7388\n",
      "Validation RMSE: 0.5499, R2 Score: 0.9328\n",
      "\n",
      "Epoch 45/100\n",
      "Training RMSE: 0.6764\n",
      "Validation RMSE: 0.5496, R2 Score: 0.9329\n",
      "\n",
      "Epoch 46/100\n",
      "Training RMSE: 0.7998\n",
      "Validation RMSE: 0.5970, R2 Score: 0.9208\n",
      "\n",
      "Epoch 47/100\n",
      "Training RMSE: 0.7316\n",
      "Validation RMSE: 0.5661, R2 Score: 0.9288\n",
      "\n",
      "Epoch 48/100\n",
      "Training RMSE: 0.6883\n",
      "Validation RMSE: 0.5273, R2 Score: 0.9382\n",
      "\n",
      "Best model updated at epoch 48 with validation RMSE: 0.5273\n",
      "Epoch 49/100\n",
      "Training RMSE: 0.6644\n",
      "Validation RMSE: 0.5352, R2 Score: 0.9364\n",
      "\n",
      "Epoch 50/100\n",
      "Training RMSE: 0.7103\n",
      "Validation RMSE: 0.6098, R2 Score: 0.9174\n",
      "\n",
      "Epoch 51/100\n",
      "Training RMSE: 0.7296\n",
      "Validation RMSE: 0.5764, R2 Score: 0.9262\n",
      "\n",
      "Epoch 52/100\n",
      "Training RMSE: 0.6666\n",
      "Validation RMSE: 0.5308, R2 Score: 0.9374\n",
      "\n",
      "Epoch 53/100\n",
      "Training RMSE: 0.6867\n",
      "Validation RMSE: 0.5402, R2 Score: 0.9352\n",
      "\n",
      "Epoch 54/100\n",
      "Training RMSE: 0.7588\n",
      "Validation RMSE: 0.5258, R2 Score: 0.9386\n",
      "\n",
      "Best model updated at epoch 54 with validation RMSE: 0.5258\n",
      "Epoch 55/100\n",
      "Training RMSE: 0.6639\n",
      "Validation RMSE: 0.5441, R2 Score: 0.9342\n",
      "\n",
      "Epoch 56/100\n",
      "Training RMSE: 0.6546\n",
      "Validation RMSE: 0.5260, R2 Score: 0.9385\n",
      "\n",
      "Epoch 57/100\n",
      "Training RMSE: 0.6864\n",
      "Validation RMSE: 0.5221, R2 Score: 0.9394\n",
      "\n",
      "Best model updated at epoch 57 with validation RMSE: 0.5221\n",
      "Epoch 58/100\n",
      "Training RMSE: 0.6476\n",
      "Validation RMSE: 0.5317, R2 Score: 0.9372\n",
      "\n",
      "Epoch 59/100\n",
      "Training RMSE: 0.6887\n",
      "Validation RMSE: 0.5335, R2 Score: 0.9368\n",
      "\n",
      "Epoch 60/100\n",
      "Training RMSE: 0.6549\n",
      "Validation RMSE: 0.5492, R2 Score: 0.9330\n",
      "\n",
      "Epoch 61/100\n",
      "Training RMSE: 0.6473\n",
      "Validation RMSE: 0.5393, R2 Score: 0.9354\n",
      "\n",
      "Epoch 62/100\n",
      "Training RMSE: 0.6646\n",
      "Validation RMSE: 0.5297, R2 Score: 0.9377\n",
      "\n",
      "Epoch 63/100\n",
      "Training RMSE: 0.6775\n",
      "Validation RMSE: 0.6024, R2 Score: 0.9194\n",
      "\n",
      "Epoch 64/100\n",
      "Training RMSE: 0.7194\n",
      "Validation RMSE: 0.5566, R2 Score: 0.9312\n",
      "\n",
      "Epoch 65/100\n",
      "Training RMSE: 0.6546\n",
      "Validation RMSE: 0.5506, R2 Score: 0.9327\n",
      "\n",
      "Epoch 66/100\n",
      "Training RMSE: 0.6529\n",
      "Validation RMSE: 0.5182, R2 Score: 0.9403\n",
      "\n",
      "Best model updated at epoch 66 with validation RMSE: 0.5182\n",
      "Epoch 67/100\n",
      "Training RMSE: 0.6130\n",
      "Validation RMSE: 0.5616, R2 Score: 0.9299\n",
      "\n",
      "Epoch 68/100\n",
      "Training RMSE: 0.6141\n",
      "Validation RMSE: 0.5111, R2 Score: 0.9420\n",
      "\n",
      "Best model updated at epoch 68 with validation RMSE: 0.5111\n",
      "Epoch 69/100\n",
      "Training RMSE: 0.6552\n",
      "Validation RMSE: 0.5358, R2 Score: 0.9362\n",
      "\n",
      "Epoch 70/100\n",
      "Training RMSE: 0.6352\n",
      "Validation RMSE: 0.5189, R2 Score: 0.9402\n",
      "\n",
      "Epoch 71/100\n",
      "Training RMSE: 0.6287\n",
      "Validation RMSE: 0.5092, R2 Score: 0.9424\n",
      "\n",
      "Best model updated at epoch 71 with validation RMSE: 0.5092\n",
      "Epoch 72/100\n",
      "Training RMSE: 0.7078\n",
      "Validation RMSE: 0.5636, R2 Score: 0.9294\n",
      "\n",
      "Epoch 73/100\n",
      "Training RMSE: 0.7901\n",
      "Validation RMSE: 0.5560, R2 Score: 0.9313\n",
      "\n",
      "Epoch 74/100\n",
      "Training RMSE: 0.7552\n",
      "Validation RMSE: 0.6612, R2 Score: 0.9029\n",
      "\n",
      "Epoch 75/100\n",
      "Training RMSE: 0.7216\n",
      "Validation RMSE: 0.5448, R2 Score: 0.9341\n",
      "\n",
      "Epoch 76/100\n",
      "Training RMSE: 0.7890\n",
      "Validation RMSE: 0.5863, R2 Score: 0.9236\n",
      "\n",
      "Epoch 77/100\n",
      "Training RMSE: 0.6614\n",
      "Validation RMSE: 0.5432, R2 Score: 0.9345\n",
      "\n",
      "Epoch 78/100\n",
      "Training RMSE: 0.6435\n",
      "Validation RMSE: 0.5160, R2 Score: 0.9409\n",
      "\n",
      "Epoch 79/100\n",
      "Training RMSE: 0.6327\n",
      "Validation RMSE: 0.5213, R2 Score: 0.9396\n",
      "\n",
      "Epoch 80/100\n",
      "Training RMSE: 0.6490\n",
      "Validation RMSE: 0.5095, R2 Score: 0.9423\n",
      "\n",
      "Epoch 81/100\n",
      "Training RMSE: 0.6185\n",
      "Validation RMSE: 0.5290, R2 Score: 0.9378\n",
      "\n",
      "Epoch 82/100\n",
      "Training RMSE: 0.6400\n",
      "Validation RMSE: 0.5185, R2 Score: 0.9403\n",
      "\n",
      "Epoch 83/100\n",
      "Training RMSE: 0.6137\n",
      "Validation RMSE: 0.5007, R2 Score: 0.9443\n",
      "\n",
      "Best model updated at epoch 83 with validation RMSE: 0.5007\n",
      "Epoch 84/100\n",
      "Training RMSE: 0.6222\n",
      "Validation RMSE: 0.5030, R2 Score: 0.9438\n",
      "\n",
      "Epoch 85/100\n",
      "Training RMSE: 0.6580\n",
      "Validation RMSE: 0.5144, R2 Score: 0.9412\n",
      "\n",
      "Epoch 86/100\n",
      "Training RMSE: 0.6296\n",
      "Validation RMSE: 0.5923, R2 Score: 0.9221\n",
      "\n",
      "Epoch 87/100\n",
      "Training RMSE: 0.6527\n",
      "Validation RMSE: 0.5006, R2 Score: 0.9443\n",
      "\n",
      "Best model updated at epoch 87 with validation RMSE: 0.5006\n",
      "Epoch 88/100\n",
      "Training RMSE: 0.6606\n",
      "Validation RMSE: 0.5517, R2 Score: 0.9324\n",
      "\n",
      "Epoch 89/100\n",
      "Training RMSE: 0.6346\n",
      "Validation RMSE: 0.5328, R2 Score: 0.9369\n",
      "\n",
      "Epoch 90/100\n",
      "Training RMSE: 0.6616\n",
      "Validation RMSE: 0.5438, R2 Score: 0.9343\n",
      "\n",
      "Epoch 91/100\n",
      "Training RMSE: 0.6566\n",
      "Validation RMSE: 0.5162, R2 Score: 0.9408\n",
      "\n",
      "Epoch 92/100\n",
      "Training RMSE: 0.5910\n",
      "Validation RMSE: 0.5091, R2 Score: 0.9424\n",
      "\n",
      "Epoch 93/100\n",
      "Training RMSE: 0.6001\n",
      "Validation RMSE: 0.5074, R2 Score: 0.9428\n",
      "\n",
      "Epoch 94/100\n",
      "Training RMSE: 0.6296\n",
      "Validation RMSE: 0.5225, R2 Score: 0.9393\n",
      "\n",
      "Epoch 95/100\n",
      "Training RMSE: 0.5705\n",
      "Validation RMSE: 0.5441, R2 Score: 0.9342\n",
      "\n",
      "Epoch 96/100\n",
      "Training RMSE: 0.6230\n",
      "Validation RMSE: 0.5159, R2 Score: 0.9409\n",
      "\n",
      "Epoch 97/100\n",
      "Training RMSE: 0.6292\n",
      "Validation RMSE: 0.6000, R2 Score: 0.9200\n",
      "\n",
      "Epoch 98/100\n",
      "Training RMSE: 0.6033\n",
      "Validation RMSE: 0.5055, R2 Score: 0.9432\n",
      "\n",
      "Epoch 99/100\n",
      "Training RMSE: 0.6070\n",
      "Validation RMSE: 0.5116, R2 Score: 0.9419\n",
      "\n",
      "Epoch 100/100\n",
      "Training RMSE: 0.6546\n",
      "Validation RMSE: 0.5161, R2 Score: 0.9408\n",
      "\n",
      "Training completed. Best model was at epoch 87 with validation RMSE: 0.5006\n"
     ]
    }
   ],
   "source": [
    "# Descriptor loader 생성\n",
    "train_loader, valid_loader, test_loader = get_dataloader(dataset_name = 'esol', data_type='Descriptors', batch_size = 128)\n",
    "\n",
    "# 학습할 모델 정의\n",
    "ds_reg_model = MLP(input_dim=210, hidden_dim = 128, num_classes = 1, dropout_rate=0.2)\n",
    "\n",
    "# train\n",
    "train_reg(ds_reg_model, train_loader, valid_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d67d4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training RMSE: 0.6134\n",
      "Validation RMSE: 0.5051, R2 Score: -0.1112\n",
      "\n",
      "Best model updated at epoch 1 with validation RMSE: 0.5051\n",
      "Epoch 2/10\n",
      "Training RMSE: 0.5003\n",
      "Validation RMSE: 0.4959, R2 Score: -0.0709\n",
      "\n",
      "Best model updated at epoch 2 with validation RMSE: 0.4959\n",
      "Epoch 3/10\n",
      "Training RMSE: 0.4955\n",
      "Validation RMSE: 0.4795, R2 Score: -0.0015\n",
      "\n",
      "Best model updated at epoch 3 with validation RMSE: 0.4795\n",
      "Epoch 4/10\n",
      "Training RMSE: 0.4893\n",
      "Validation RMSE: 0.4826, R2 Score: -0.0145\n",
      "\n",
      "Epoch 5/10\n",
      "Training RMSE: 0.4832\n",
      "Validation RMSE: 0.4796, R2 Score: -0.0019\n",
      "\n",
      "Epoch 6/10\n",
      "Training RMSE: 0.4820\n",
      "Validation RMSE: 0.4809, R2 Score: -0.0073\n",
      "\n",
      "Epoch 7/10\n",
      "Training RMSE: 0.4924\n",
      "Validation RMSE: 0.4808, R2 Score: -0.0068\n",
      "\n",
      "Epoch 8/10\n",
      "Training RMSE: 0.4982\n",
      "Validation RMSE: 0.4862, R2 Score: -0.0297\n",
      "\n",
      "Epoch 9/10\n",
      "Training RMSE: 0.4897\n",
      "Validation RMSE: 0.4802, R2 Score: -0.0043\n",
      "\n",
      "Epoch 10/10\n",
      "Training RMSE: 0.4925\n",
      "Validation RMSE: 0.4837, R2 Score: -0.0189\n",
      "\n",
      "Training completed. Best model was at epoch 3 with validation RMSE: 0.4795\n"
     ]
    }
   ],
   "source": [
    "# Token loader 생성\n",
    "train_loader, valid_loader, test_loader = get_dataloader(dataset_name = 'esol', data_type='Token', batch_size = 128)\n",
    "\n",
    "# 학습할 모델 정의\n",
    "token_reg_model = Conv1d(vocab_num=39, seq_len=97, emb_dim=64, hidden_size=32, kernel_size = 4, num_classes=1)\n",
    "\n",
    "# train\n",
    "train_reg(token_reg_model, train_loader, valid_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee5847bb-543a-4b51-93fe-c5f2d214fbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Training RMSE: 1.9194\n",
      "Validation RMSE: 1.9734, R2 Score: 0.1349\n",
      "\n",
      "Best model updated at epoch 1 with validation RMSE: 1.9734\n",
      "Epoch 2/100\n",
      "Training RMSE: 1.2923\n",
      "Validation RMSE: 1.7688, R2 Score: 0.3050\n",
      "\n",
      "Best model updated at epoch 2 with validation RMSE: 1.7688\n",
      "Epoch 3/100\n",
      "Training RMSE: 1.2405\n",
      "Validation RMSE: 1.1164, R2 Score: 0.7231\n",
      "\n",
      "Best model updated at epoch 3 with validation RMSE: 1.1164\n",
      "Epoch 4/100\n",
      "Training RMSE: 1.2084\n",
      "Validation RMSE: 1.1161, R2 Score: 0.7233\n",
      "\n",
      "Best model updated at epoch 4 with validation RMSE: 1.1161\n",
      "Epoch 5/100\n",
      "Training RMSE: 1.2652\n",
      "Validation RMSE: 1.2352, R2 Score: 0.6610\n",
      "\n",
      "Epoch 6/100\n",
      "Training RMSE: 1.1217\n",
      "Validation RMSE: 1.0227, R2 Score: 0.7676\n",
      "\n",
      "Best model updated at epoch 6 with validation RMSE: 1.0227\n",
      "Epoch 7/100\n",
      "Training RMSE: 1.0520\n",
      "Validation RMSE: 1.2283, R2 Score: 0.6648\n",
      "\n",
      "Epoch 8/100\n",
      "Training RMSE: 1.1259\n",
      "Validation RMSE: 0.8630, R2 Score: 0.8345\n",
      "\n",
      "Best model updated at epoch 8 with validation RMSE: 0.8630\n",
      "Epoch 9/100\n",
      "Training RMSE: 1.0042\n",
      "Validation RMSE: 0.9896, R2 Score: 0.7824\n",
      "\n",
      "Epoch 10/100\n",
      "Training RMSE: 1.0668\n",
      "Validation RMSE: 0.9025, R2 Score: 0.8191\n",
      "\n",
      "Epoch 11/100\n",
      "Training RMSE: 0.9695\n",
      "Validation RMSE: 0.8847, R2 Score: 0.8261\n",
      "\n",
      "Epoch 12/100\n",
      "Training RMSE: 1.1081\n",
      "Validation RMSE: 0.9153, R2 Score: 0.8139\n",
      "\n",
      "Epoch 13/100\n",
      "Training RMSE: 0.9844\n",
      "Validation RMSE: 1.2908, R2 Score: 0.6299\n",
      "\n",
      "Epoch 14/100\n",
      "Training RMSE: 1.0661\n",
      "Validation RMSE: 0.8585, R2 Score: 0.8363\n",
      "\n",
      "Best model updated at epoch 14 with validation RMSE: 0.8585\n",
      "Epoch 15/100\n",
      "Training RMSE: 1.2607\n",
      "Validation RMSE: 1.1868, R2 Score: 0.6871\n",
      "\n",
      "Epoch 16/100\n",
      "Training RMSE: 1.1091\n",
      "Validation RMSE: 1.1927, R2 Score: 0.6840\n",
      "\n",
      "Epoch 17/100\n",
      "Training RMSE: 1.0912\n",
      "Validation RMSE: 0.8756, R2 Score: 0.8297\n",
      "\n",
      "Epoch 18/100\n",
      "Training RMSE: 1.0277\n",
      "Validation RMSE: 1.0712, R2 Score: 0.7451\n",
      "\n",
      "Epoch 19/100\n",
      "Training RMSE: 1.0084\n",
      "Validation RMSE: 0.8053, R2 Score: 0.8559\n",
      "\n",
      "Best model updated at epoch 19 with validation RMSE: 0.8053\n",
      "Epoch 20/100\n",
      "Training RMSE: 1.1574\n",
      "Validation RMSE: 0.8150, R2 Score: 0.8525\n",
      "\n",
      "Epoch 21/100\n",
      "Training RMSE: 1.0300\n",
      "Validation RMSE: 0.8548, R2 Score: 0.8377\n",
      "\n",
      "Epoch 22/100\n",
      "Training RMSE: 1.0547\n",
      "Validation RMSE: 0.8441, R2 Score: 0.8417\n",
      "\n",
      "Epoch 23/100\n",
      "Training RMSE: 0.9486\n",
      "Validation RMSE: 1.0209, R2 Score: 0.7685\n",
      "\n",
      "Epoch 24/100\n",
      "Training RMSE: 0.9330\n",
      "Validation RMSE: 0.9325, R2 Score: 0.8068\n",
      "\n",
      "Epoch 25/100\n",
      "Training RMSE: 0.9362\n",
      "Validation RMSE: 0.8681, R2 Score: 0.8326\n",
      "\n",
      "Epoch 26/100\n",
      "Training RMSE: 1.0774\n",
      "Validation RMSE: 0.8567, R2 Score: 0.8369\n",
      "\n",
      "Epoch 27/100\n",
      "Training RMSE: 0.9537\n",
      "Validation RMSE: 0.9218, R2 Score: 0.8112\n",
      "\n",
      "Epoch 28/100\n",
      "Training RMSE: 0.9840\n",
      "Validation RMSE: 1.2668, R2 Score: 0.6435\n",
      "\n",
      "Epoch 29/100\n",
      "Training RMSE: 0.9804\n",
      "Validation RMSE: 0.8723, R2 Score: 0.8310\n",
      "\n",
      "Epoch 30/100\n",
      "Training RMSE: 0.9305\n",
      "Validation RMSE: 0.8629, R2 Score: 0.8346\n",
      "\n",
      "Epoch 31/100\n",
      "Training RMSE: 0.9400\n",
      "Validation RMSE: 0.8376, R2 Score: 0.8441\n",
      "\n",
      "Epoch 32/100\n",
      "Training RMSE: 0.8723\n",
      "Validation RMSE: 0.8023, R2 Score: 0.8570\n",
      "\n",
      "Best model updated at epoch 32 with validation RMSE: 0.8023\n",
      "Epoch 33/100\n",
      "Training RMSE: 0.9001\n",
      "Validation RMSE: 0.7573, R2 Score: 0.8726\n",
      "\n",
      "Best model updated at epoch 33 with validation RMSE: 0.7573\n",
      "Epoch 34/100\n",
      "Training RMSE: 0.7520\n",
      "Validation RMSE: 0.8327, R2 Score: 0.8460\n",
      "\n",
      "Epoch 35/100\n",
      "Training RMSE: 0.8018\n",
      "Validation RMSE: 0.6866, R2 Score: 0.8953\n",
      "\n",
      "Best model updated at epoch 35 with validation RMSE: 0.6866\n",
      "Epoch 36/100\n",
      "Training RMSE: 0.8856\n",
      "Validation RMSE: 0.7641, R2 Score: 0.8703\n",
      "\n",
      "Epoch 37/100\n",
      "Training RMSE: 0.7768\n",
      "Validation RMSE: 0.9642, R2 Score: 0.7935\n",
      "\n",
      "Epoch 38/100\n",
      "Training RMSE: 1.0046\n",
      "Validation RMSE: 0.7403, R2 Score: 0.8783\n",
      "\n",
      "Epoch 39/100\n",
      "Training RMSE: 0.8037\n",
      "Validation RMSE: 0.8608, R2 Score: 0.8354\n",
      "\n",
      "Epoch 40/100\n",
      "Training RMSE: 0.7786\n",
      "Validation RMSE: 0.6390, R2 Score: 0.9093\n",
      "\n",
      "Best model updated at epoch 40 with validation RMSE: 0.6390\n",
      "Epoch 41/100\n",
      "Training RMSE: 0.8876\n",
      "Validation RMSE: 0.8494, R2 Score: 0.8397\n",
      "\n",
      "Epoch 42/100\n",
      "Training RMSE: 0.8805\n",
      "Validation RMSE: 1.0907, R2 Score: 0.7357\n",
      "\n",
      "Epoch 43/100\n",
      "Training RMSE: 1.0431\n",
      "Validation RMSE: 0.8593, R2 Score: 0.8360\n",
      "\n",
      "Epoch 44/100\n",
      "Training RMSE: 1.0783\n",
      "Validation RMSE: 1.0673, R2 Score: 0.7469\n",
      "\n",
      "Epoch 45/100\n",
      "Training RMSE: 0.9894\n",
      "Validation RMSE: 1.0168, R2 Score: 0.7703\n",
      "\n",
      "Epoch 46/100\n",
      "Training RMSE: 0.8894\n",
      "Validation RMSE: 0.8057, R2 Score: 0.8558\n",
      "\n",
      "Epoch 47/100\n",
      "Training RMSE: 0.8171\n",
      "Validation RMSE: 0.8091, R2 Score: 0.8546\n",
      "\n",
      "Epoch 48/100\n",
      "Training RMSE: 0.7940\n",
      "Validation RMSE: 0.6993, R2 Score: 0.8914\n",
      "\n",
      "Epoch 49/100\n",
      "Training RMSE: 0.8188\n",
      "Validation RMSE: 0.7097, R2 Score: 0.8881\n",
      "\n",
      "Epoch 50/100\n",
      "Training RMSE: 0.7674\n",
      "Validation RMSE: 0.7467, R2 Score: 0.8761\n",
      "\n",
      "Epoch 51/100\n",
      "Training RMSE: 1.0366\n",
      "Validation RMSE: 0.8442, R2 Score: 0.8417\n",
      "\n",
      "Epoch 52/100\n",
      "Training RMSE: 0.8883\n",
      "Validation RMSE: 1.2334, R2 Score: 0.6621\n",
      "\n",
      "Epoch 53/100\n",
      "Training RMSE: 0.8790\n",
      "Validation RMSE: 0.6724, R2 Score: 0.8996\n",
      "\n",
      "Epoch 54/100\n",
      "Training RMSE: 0.7810\n",
      "Validation RMSE: 0.9063, R2 Score: 0.8175\n",
      "\n",
      "Epoch 55/100\n",
      "Training RMSE: 0.9125\n",
      "Validation RMSE: 0.7397, R2 Score: 0.8784\n",
      "\n",
      "Epoch 56/100\n",
      "Training RMSE: 0.9314\n",
      "Validation RMSE: 0.7005, R2 Score: 0.8910\n",
      "\n",
      "Epoch 57/100\n",
      "Training RMSE: 0.8115\n",
      "Validation RMSE: 0.7797, R2 Score: 0.8650\n",
      "\n",
      "Epoch 58/100\n",
      "Training RMSE: 0.7823\n",
      "Validation RMSE: 0.8054, R2 Score: 0.8559\n",
      "\n",
      "Epoch 59/100\n",
      "Training RMSE: 0.9315\n",
      "Validation RMSE: 0.7968, R2 Score: 0.8589\n",
      "\n",
      "Epoch 60/100\n",
      "Training RMSE: 1.0651\n",
      "Validation RMSE: 0.8320, R2 Score: 0.8462\n",
      "\n",
      "Epoch 61/100\n",
      "Training RMSE: 0.7743\n",
      "Validation RMSE: 0.8694, R2 Score: 0.8321\n",
      "\n",
      "Epoch 62/100\n",
      "Training RMSE: 0.7776\n",
      "Validation RMSE: 0.7750, R2 Score: 0.8666\n",
      "\n",
      "Epoch 63/100\n",
      "Training RMSE: 0.7823\n",
      "Validation RMSE: 0.8030, R2 Score: 0.8567\n",
      "\n",
      "Epoch 64/100\n",
      "Training RMSE: 0.8108\n",
      "Validation RMSE: 0.7581, R2 Score: 0.8723\n",
      "\n",
      "Epoch 65/100\n",
      "Training RMSE: 0.7811\n",
      "Validation RMSE: 0.7285, R2 Score: 0.8821\n",
      "\n",
      "Epoch 66/100\n",
      "Training RMSE: 0.8185\n",
      "Validation RMSE: 0.6440, R2 Score: 0.9079\n",
      "\n",
      "Epoch 67/100\n",
      "Training RMSE: 0.7385\n",
      "Validation RMSE: 0.6728, R2 Score: 0.8995\n",
      "\n",
      "Epoch 68/100\n",
      "Training RMSE: 0.7291\n",
      "Validation RMSE: 0.7327, R2 Score: 0.8808\n",
      "\n",
      "Epoch 69/100\n",
      "Training RMSE: 1.0661\n",
      "Validation RMSE: 0.8428, R2 Score: 0.8422\n",
      "\n",
      "Epoch 70/100\n",
      "Training RMSE: 0.7723\n",
      "Validation RMSE: 0.8905, R2 Score: 0.8238\n",
      "\n",
      "Epoch 71/100\n",
      "Training RMSE: 0.8839\n",
      "Validation RMSE: 0.7316, R2 Score: 0.8811\n",
      "\n",
      "Epoch 72/100\n",
      "Training RMSE: 0.7620\n",
      "Validation RMSE: 0.7620, R2 Score: 0.8710\n",
      "\n",
      "Epoch 73/100\n",
      "Training RMSE: 0.7440\n",
      "Validation RMSE: 0.8280, R2 Score: 0.8477\n",
      "\n",
      "Epoch 74/100\n",
      "Training RMSE: 1.0041\n",
      "Validation RMSE: 0.7098, R2 Score: 0.8881\n",
      "\n",
      "Epoch 75/100\n",
      "Training RMSE: 0.9474\n",
      "Validation RMSE: 0.9394, R2 Score: 0.8040\n",
      "\n",
      "Epoch 76/100\n",
      "Training RMSE: 0.8423\n",
      "Validation RMSE: 0.8108, R2 Score: 0.8540\n",
      "\n",
      "Epoch 77/100\n",
      "Training RMSE: 0.8635\n",
      "Validation RMSE: 0.8921, R2 Score: 0.8232\n",
      "\n",
      "Epoch 78/100\n",
      "Training RMSE: 0.8456\n",
      "Validation RMSE: 1.0031, R2 Score: 0.7764\n",
      "\n",
      "Epoch 79/100\n",
      "Training RMSE: 0.7861\n",
      "Validation RMSE: 0.7688, R2 Score: 0.8687\n",
      "\n",
      "Epoch 80/100\n",
      "Training RMSE: 0.7764\n",
      "Validation RMSE: 0.8079, R2 Score: 0.8550\n",
      "\n",
      "Epoch 81/100\n",
      "Training RMSE: 0.7512\n",
      "Validation RMSE: 0.7274, R2 Score: 0.8825\n",
      "\n",
      "Epoch 82/100\n",
      "Training RMSE: 0.8455\n",
      "Validation RMSE: 0.7013, R2 Score: 0.8907\n",
      "\n",
      "Epoch 83/100\n",
      "Training RMSE: 0.7367\n",
      "Validation RMSE: 0.6290, R2 Score: 0.9121\n",
      "\n",
      "Best model updated at epoch 83 with validation RMSE: 0.6290\n",
      "Epoch 84/100\n",
      "Training RMSE: 0.7652\n",
      "Validation RMSE: 0.6835, R2 Score: 0.8962\n",
      "\n",
      "Epoch 85/100\n",
      "Training RMSE: 0.7246\n",
      "Validation RMSE: 0.6663, R2 Score: 0.9014\n",
      "\n",
      "Epoch 86/100\n",
      "Training RMSE: 0.7560\n",
      "Validation RMSE: 0.7011, R2 Score: 0.8908\n",
      "\n",
      "Epoch 87/100\n",
      "Training RMSE: 0.7206\n",
      "Validation RMSE: 0.7918, R2 Score: 0.8607\n",
      "\n",
      "Epoch 88/100\n",
      "Training RMSE: 0.6793\n",
      "Validation RMSE: 0.6735, R2 Score: 0.8992\n",
      "\n",
      "Epoch 89/100\n",
      "Training RMSE: 0.6756\n",
      "Validation RMSE: 0.6156, R2 Score: 0.9158\n",
      "\n",
      "Best model updated at epoch 89 with validation RMSE: 0.6156\n",
      "Epoch 90/100\n",
      "Training RMSE: 0.6767\n",
      "Validation RMSE: 0.6682, R2 Score: 0.9008\n",
      "\n",
      "Epoch 91/100\n",
      "Training RMSE: 0.6998\n",
      "Validation RMSE: 0.6469, R2 Score: 0.9070\n",
      "\n",
      "Epoch 92/100\n",
      "Training RMSE: 0.6750\n",
      "Validation RMSE: 0.6769, R2 Score: 0.8982\n",
      "\n",
      "Epoch 93/100\n",
      "Training RMSE: 0.6768\n",
      "Validation RMSE: 0.6636, R2 Score: 0.9022\n",
      "\n",
      "Epoch 94/100\n",
      "Training RMSE: 0.6739\n",
      "Validation RMSE: 0.5853, R2 Score: 0.9239\n",
      "\n",
      "Best model updated at epoch 94 with validation RMSE: 0.5853\n",
      "Epoch 95/100\n",
      "Training RMSE: 0.7462\n",
      "Validation RMSE: 0.5700, R2 Score: 0.9278\n",
      "\n",
      "Best model updated at epoch 95 with validation RMSE: 0.5700\n",
      "Epoch 96/100\n",
      "Training RMSE: 0.6895\n",
      "Validation RMSE: 0.8573, R2 Score: 0.8367\n",
      "\n",
      "Epoch 97/100\n",
      "Training RMSE: 0.7424\n",
      "Validation RMSE: 0.8176, R2 Score: 0.8515\n",
      "\n",
      "Epoch 98/100\n",
      "Training RMSE: 0.7919\n",
      "Validation RMSE: 0.6988, R2 Score: 0.8915\n",
      "\n",
      "Epoch 99/100\n",
      "Training RMSE: 0.7532\n",
      "Validation RMSE: 0.6860, R2 Score: 0.8954\n",
      "\n",
      "Epoch 100/100\n",
      "Training RMSE: 0.6943\n",
      "Validation RMSE: 0.6382, R2 Score: 0.9095\n",
      "\n",
      "Training completed. Best model was at epoch 95 with validation RMSE: 0.5700\n"
     ]
    }
   ],
   "source": [
    "# Graph loader 생성\n",
    "train_loader, valid_loader, test_loader = get_dataloader(dataset_name = 'esol', data_type='Graph', batch_size = 128)\n",
    "\n",
    "# 학습할 모델 정의\n",
    "g_reg_model = GINConvNet(input_dim=9, dim_h=128)\n",
    "\n",
    "# train\n",
    "train_reg(g_reg_model, train_loader, valid_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8239b478",
   "metadata": {},
   "source": [
    "### Regression 모델 테스트 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af135117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_regression(model, test_loader, save_file='Results_regression.csv'):\n",
    "    model = model.to(device)\n",
    "    model.eval()    \n",
    "    criterion = nn.MSELoss()  # Changed to MSE for regression\n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            y = data.y\n",
    "            \n",
    "            output = model(data)\n",
    "            preds = output.cpu().numpy().ravel()  # Removed sigmoid, direct output for regression\n",
    "            all_preds.append(preds)\n",
    "            all_targets.append(y.cpu().numpy())\n",
    "            \n",
    "            # Loss calculation\n",
    "            test_loss += criterion(output, y).item()\n",
    "            \n",
    "        # Concatenate predictions and targets\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "    \n",
    "        # Calculate regression metrics\n",
    "        mse = np.mean((all_preds - all_targets) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = np.mean(np.abs(all_preds - all_targets))\n",
    "        r2 = r2_score(all_targets, all_preds)\n",
    "    \n",
    "        # Average loss\n",
    "        test_loss /= len(test_loader)\n",
    "    \n",
    "        # Store metrics\n",
    "        metrics = {\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"R²\": r2\n",
    "        }\n",
    "    \n",
    "        # Print results\n",
    "        print(\"\\nTest Performance Metrics:\")\n",
    "        print(tabulate(pd.DataFrame(metrics, index=[\"Metric Value\"]).T, \n",
    "                      headers=\"keys\", \n",
    "                      tablefmt=\"fancy_grid\"))\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fda38af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance Metrics:\n",
      "╒══════╤════════════════╕\n",
      "│      │   Metric Value │\n",
      "╞══════╪════════════════╡\n",
      "│ MSE  │       7.68855  │\n",
      "├──────┼────────────────┤\n",
      "│ RMSE │       2.77282  │\n",
      "├──────┼────────────────┤\n",
      "│ MAE  │       2.1769   │\n",
      "├──────┼────────────────┤\n",
      "│ R²   │       0.836798 │\n",
      "╘══════╧════════════════╛\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MSE': 7.688552,\n",
       " 'RMSE': 2.7728238,\n",
       " 'MAE': 2.1769023,\n",
       " 'R²': 0.8367981910705566}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Graph loader 생성\n",
    "train_loader, valid_loader, test_loader = get_dataloader(dataset_name = 'esol', data_type='Graph', batch_size = 128)\n",
    "g_reg_model = GINConvNet(input_dim=9, dim_h=128)\n",
    "g_reg_model.load_state_dict(torch.load(\"best_epoch.pth\"))\n",
    "test_regression(g_reg_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b25090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
